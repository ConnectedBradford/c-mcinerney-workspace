{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6d5d9a-a6b3-4471-82c7-317ece56bbfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Entropy and Mutual information\n",
    "\n",
    "The purpose of this script is to calculate the entropy of feature sets, and the mutual information between the caseness variable (i.e. record of a SNOMED CT code for conditions indicative of complex mental health difficulties) and feature sets whose entropy is at least as great as the caseness variable's.\n",
    "\n",
    "This Jupyter notebook runs \"UNSEEN create feature set array.IPYNB\" on which it depends, and \"UNSEEN create caseness array.IPYNB\" on which the feature-set Jupyter notebook depends.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e91e9e-05e9-466e-b6da-9743e8c41e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No Python libraries need importing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47159b04-f348-4084-ad6a-f698384b3979",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Run \"UNSEEN create feature set array.IPYNB\", which runs \"UNSEEN create caseness array.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00341cd4-abb5-4377-9edc-20832f80f759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ./\"UNSEEN create feature set array.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f085b218-7849-419d-848b-2d42afef00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caseness variable entropy =  0.4 nats\n",
      "Caseness variable scaled entropy =  57.7 %\n",
      "Hit rate (all) = 13.7 %\n",
      "Hit rate (none) = 86.3 %\n",
      "Odds (No CMHD : CMHD) =  6.3 times less likely to have CMHD than to have it.\n"
     ]
    }
   ],
   "source": [
    "%run ./\"UNSEEN create caseness array.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2018413-fe48-40f4-bfec-196b6ff7da3f",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464d5447-b13d-48ca-acaa-c58113119228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate template for storing entropy.\n",
    "feature_entropy_TEMPLATE =\\\n",
    "    pandas.DataFrame(columns = ['Feature set', 'Entropy'])\n",
    "\n",
    "# Instantiate template for storing mutual information.\n",
    "feature_mutual_information_TEMPLATE =\\\n",
    "    pandas.DataFrame(columns = ['Feature set', 'Mutual information'])\n",
    "\n",
    "# Instantiate storage for features that are dropped due to low entropy.\n",
    "f_to_drop_TEMPLATE =\\\n",
    "    pandas.DataFrame(columns = ['Dropped feature set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7319adb-f1af-4489-84b8-ddfee2b637ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate the entropy and two-way mutual information of the feature sets and the caseness.\n",
    "\n",
    "Our focus is mutual information but I calculate the entropy of features so that I don't calculate the mutual information for any features whose entropy is less than that of the caseness variable. Justification for this action is based on the fact that the mutual information between the caseness variable and any feature will be less than or equal to the lesser entropy of the caseness or feature, i.e. $I(X_{i};CMHD) ≤ min\\{H(X_{i}), H(CMHD)\\}$. We don’t want any feature set that is worse than no feature set (i.e. having only the caseness prevalence to predict a random outcome value) so we don’t bother with any feature set that will lower the possible mutual information. Two-way mutual information* will not be calculated for those features whose entropy is less than the caseness variable's entropy. The dropped variables are indicated in the `f_to_drop` pandas.DataFrame.\n",
    "\n",
    "First, two-way mutual information will be calculated between the caseness variable and individual feature sets. Secondly, two-way mutual information will be calculated between the caseness variable and pair-composites of feature sets. These pair composites are individual feature sets that amalgamate two feature sets into a new binary definition, where values are `0` if both component feature sets are zero and `1` otherwise**. More-complicated encoding is possible, e.g. a different level for every combination of values from each component feature set. Further code extends these feature-set compositions up to quintuplet composites (i.e. amalgamating five feature sets into a single binary variable).\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "__\\*__ _Initially, the plan was to use $k$-way mutual information for $k>2$ but the meaning of these mutual information values is controversial at best. I side with [Krippendorf's assessment](https://sci-hub.wf/10.1080/03081070902993160) , which renders 3-way mutual information interpretable but not any higher-order mutual information statistics (yet?). I decided to stick with two-way mutual information using composite feature sets so that I am comparing the same statistic across individual and composite feature sets._\n",
    "\n",
    "__\\**__ _Other encodings will be trialled at a later date. If a feature set contains more than one feature, then it will be represented in three ways: OR, AND, and multinomial. The OR representation (alternative called the at-least-one representation) is a binary variable with a value of `0` if the component features are all zero, and `1` otherwise. The AND (alternative called the all-present representation) representation is a binary variable with a value of `1` if all component features are one, and `0` otherwise. The multinomial representation is a multinomial variable with values for each of the possible combinations of component features’ values. For example, given a feature set of two features $A=\\{0,1\\}$ and $B=\\{0,1\\}$, their multinomial feature-set representation would be $C=\\{0,1,2,3\\}$, where $C=0=(A=0\\   AND\\   B=0)$, $C=1=(A=0\\   AND\\   B=1)$, $C=2=(A=1\\  AND\\  B=0)$, and $C=3=(A=1\\   AND\\   B=1)$._\n",
    "\n",
    "### Entropy and two-way mutual information of individual feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c14dff-e3dd-4e92-9986-bb70dcc92076",
   "metadata": {},
   "source": [
    "********************\n",
    "Storing all batches of calculations is taking too much storage space. I was doing this initially so that I could review the output of each stage of the workflow. It looks like the storage constraint means I will have to include the entire workflow at once and only produce the final output.\n",
    "********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f4c5a5-ae2f-4c5e-a742-82197150243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 batch(es) of feature sets processed.\n",
      "216 / 216 feature sets dropped due to low entropy.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate specific storage for mutual information.\n",
    "feature_MI_individual_ORrep = feature_mutual_information_TEMPLATE\n",
    "# Instantiate batch number.\n",
    "batch = 0\n",
    "# Instantiate tally of feature sets that are dropped due to low entropy.\n",
    "drop_tally = 0\n",
    "\n",
    "# Calculate entropy and mutual information, and store the values.\n",
    "for i_featureSet in featureSet_array.columns[featureSet_array.columns != 'person_id']:\n",
    "    if len(feature_MI_individual_ORrep) > 999:\n",
    "        # Increment batch.\n",
    "        batch += 1\n",
    "            \n",
    "        # Make an interim save of results.\n",
    "        feature_MI_individual_ORrep.to_csv(\"Mutual information saves/\"+\\\n",
    "                                           \"Individuals/\"+\\\n",
    "                                           \"UNSEEN feature set_MutInfo_individual_ORrep_batch\"+\\\n",
    "                                           str(batch)+\\\n",
    "                                           \".csv\", index = False)\n",
    "        # Instantiate new storage.\n",
    "        feature_MI_individual_ORrep = feature_mutual_information_TEMPLATE\n",
    "    else:\n",
    "        name_var = i_featureSet\n",
    "        \n",
    "        # Update the feature set id table.\n",
    "        # ## This will only be done for individual feature sets because \n",
    "        # ## higher-rder feature sets can be algorithmically define, which\n",
    "        # ## is more efficient for storage.\n",
    "        featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                ['Feature set ID', 'Feature Set 1',]] = [name_var]\n",
    "        \n",
    "        # Define the feature set's values.\n",
    "        # ## In this case, the individual feature set is defined as 0 when the feature is 0,\n",
    "        # ## and 1 otherwise. This is the \"OR\" or \"at least one\" encoding.\n",
    "        binary_var = featureSet_array[i_featureSet] == 0\n",
    "        # Calculate the mutual information for the individual feature set.\n",
    "        f_MI = sklearn.metrics.mutual_info_score(binary_var, caseness_array['CMHD'])\n",
    "        # Only store the mutual information if it is greater than or equal\n",
    "        # to the entropy of the outcome.\n",
    "        if f_MI < entropy_caseness:\n",
    "            drop_tally += 1\n",
    "            continue\n",
    "        else:\n",
    "            # Store.\n",
    "            feature_MI_individual_ORrep.loc[len(feature_MI_individual_ORrep)] = \\\n",
    "                name_var, f_MI\n",
    "\n",
    "# Increment counter.\n",
    "batch += 1\n",
    "\n",
    "# Final save.\n",
    "if len(feature_MI_individual_ORrep) != 0:\n",
    "    feature_MI_individual_ORrep.to_csv(\"Mutual information saves/\"+\\\n",
    "                                       \"Individuals/\"+\\\n",
    "                                       \"UNSEEN feature set_MutInfo_individual_ORrep_batch\"+\\\n",
    "                                       str(batch)+\\\n",
    "                                       \".csv\",\n",
    "                                       index = False)\n",
    "\n",
    "# Feedback messages.\n",
    "print(str(batch), \"batch(es) of feature sets processed.\")\n",
    "print(str(drop_tally), \"/\",\n",
    "      str(len(featureSet_array.columns)-1),\n",
    "      \"feature sets dropped due to low entropy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc764b31-a1d0-4ede-8d7a-1b09b0dcc03e",
   "metadata": {},
   "source": [
    "#### Initial results\n",
    "\n",
    "__\\*__ _Note: these initial results were calculated using a previous version of the script where the mutual information of all feature sets was saved. This approach was dropped in favour of only saving mutual information values for feature sets whose mutual information with the caseness variable is greater than the entropy of the caseness variable._\n",
    "<br/><br/><br/>\n",
    "\n",
    "All individual feature sets score very low for two-way mutual information: all less than 0.05. A $I_{2}=0.05$ represents 7.9% of the theoretical maximal situatons where the feature set either _exactly is_ the caseness variable or _is exactly not_ the variable. The top five individal feature sets (which have $I_{2}≥0.033$) are defined as having at least one recording of the following SNOMED CT codes in their primary-care electronic health records:\n",
    "\n",
    "| SNOMED code | Feature set | Topic | Mutual Information | Scaled mutual information | Odds ratio | P(CMHD given X=1) | P(CMHD given X=0) |\n",
    "| ----------- | ----------- | ----- | ------------------ | ------------------------- | ---------- | ----------------- | ----------------- |\n",
    "| 314530002 | Medication review done | Medication | ~0.055 | 7.9% | 8.5 | 4.1 | 26.8 |\n",
    "| 182888003 | Medication requested  | Medication | ~0.035 | 5.0% | 4.9 | 7.9 | 29.5 |\n",
    "| 1018251000000107 | Serum alanine aminotransferase level (observable entity) | Liver test | ~0.033 | 4.7% | 5.5 | 4.7 | 21.6 |\n",
    "| 1000621000000104 | Serum alkaline phosphatase level | Liver test | ~0.033 | 4.7% | 5.5 | 4.7 | 21.5 |\n",
    "| 1022791000000101 | TSH (thyroid stimulating hormone) level | Endocrine | ~0.033 | 4.7% | 5.0 | 5.4 | 22.5 |\n",
    "\n",
    "The paradoxes of commonly-reported classification statistics are clearly shown. A medication _review_ has the largest odds ratio but the probability of having a record of the caseness variable given that medication was _requested_ is higher. One might propose that a record of a medication request is a better indicator than a record of a medication review, if they prefer the probability statistic over the odds-ratio statistic. But when we look at the probability of the caseness variable given that there is _no_ record of medication being requested, we see that this is also the largest of the top five feature sets! The odds ratio tries to balance these ambiguous probability statistics but it is, therefore, harder to interpret. Note, the odds ratio for a record of a medication _review_ scores better than for a record of medication _request_ because the distinction between the ambiguous probabilities is greater (multiplicatively).\n",
    "\n",
    "The scaled mutual information is simply a percentage measure of how much the caseness variable is described by the feature set (in terms of information). Unlike the odds ratio, it will give the same value whether the odds are multiplicatively greater or less than equal - e.g. $I_{2}$ will be the same for $OR = 4.0$ and $OR = 0.25$  - so it only measures magnitude of association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98143cb2-17a8-4712-a00e-14038338a1a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Entropy and two-way mutual information of pair-composite feature sets and the caseness variable.\n",
    "The nested FOR LOOPs below also update the Feature Set ID table with the new features.\n",
    "\n",
    "\n",
    "*********************\n",
    "Why are MI values < 0.4 being saved?\n",
    "*********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e9dbe96-985c-4065-83c5-3d7f93f6501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 batch(es) of feature sets processed.\n",
      "0 / 23220.0 feature sets dropped due to low entropy.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate specific storage for mutual information.\n",
    "feature_MI_pair_ORrep = feature_mutual_information_TEMPLATE\n",
    "# Instantiate batch number.\n",
    "batch = 0\n",
    "# Instantiate tally of feature sets that are dropped due to low entropy.\n",
    "drop_tally = 0\n",
    "\n",
    "# Calculate entropy and mutual information, and store the values.\n",
    "for i_featureSet in featureSet_array.columns[featureSet_array.columns != 'person_id']:\n",
    "    for j_featureSet in featureSet_array.columns[featureSet_array.columns != 'person_id']:\n",
    "        if len(feature_MI_pair_ORrep) > 10:\n",
    "            break\n",
    "        if len(feature_MI_pair_ORrep) > 999:\n",
    "            # Increment batch.\n",
    "            batch += 1\n",
    "                \n",
    "            # Make an interim save of results.\n",
    "            feature_MI_pair_ORrep.to_csv(\"Mutual information saves/Pairs/\"+\\\n",
    "                  \"UNSEEN feature set_MutInfo_pair_ORrep_batch\"+\\\n",
    "                                               str(batch)+\\\n",
    "                                               \".csv\", index = False)\n",
    "            # Instantiate new storage.\n",
    "            feature_MI_pair_ORrep = feature_mutual_information_TEMPLATE\n",
    "        else:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if i_featureSet == j_featureSet:\n",
    "                continue\n",
    "            else:\n",
    "                # Create the feature ID for the pair-composite feature set.\n",
    "                name_var = \"-\".join([i_featureSet, j_featureSet])\n",
    "\n",
    "#                # Update the feature set id table.\n",
    "#                featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "#                                        ['Feature set ID', 'Feature Set 1', 'Feature Set 2']] = \\\n",
    "#                    [name_var, i_featureSet, j_featureSet]\n",
    "\n",
    "                # Define the pair-composite feature set values.\n",
    "                # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "                # ## sets are 0, and 1 otherwise. This is the \"OR\" or \"at least one\" encoding.\n",
    "                binary_var = \\\n",
    "                    pandas.DataFrame(data = {\n",
    "                                              'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                              'j_binary_var' : featureSet_array[j_featureSet] == 0\n",
    "                                             }\n",
    "                                    ).all(True)\n",
    "\n",
    "                # Calculate the mutual information for the pair-composite feature set.\n",
    "                f_MI = sklearn.metrics.mutual_info_score(binary_var, caseness_array['CMHD'])\n",
    "                print(\"f_MI =\",f_MI)\n",
    "                if f_MI < entropy_caseness:\n",
    "                    drop_tally += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    # Calculate the mutual information for the pair-composite feature set.\n",
    "                    feature_MI_pair_ORrep.loc[len(feature_MI_pair_ORrep)] = \\\n",
    "                        name_var, f_MI\n",
    "\n",
    "# Increment counter.\n",
    "batch += 1\n",
    "\n",
    "# Final save.\n",
    "if len(feature_MI_pair_ORrep) != 0:\n",
    "    feature_MI_pair_ORrep.to_csv(\"Mutual information saves/Pairs/\"+\\\n",
    "                      \"UNSEEN feature set_MutInfo_pair_ORrep_batch\"+\\\n",
    "                                                   str(batch)+\\\n",
    "                                                   \".csv\",\n",
    "                                       index = False)\n",
    "\n",
    "# Feedback messages.\n",
    "print(str(batch), \"batch(es) of feature sets processed.\")\n",
    "count_of_features = len(featureSet_array.columns)-1\n",
    "count_of_pairs = (pow(count_of_features,2)-count_of_features) / 2\n",
    "print(str(drop_tally), \"/\", str(count_of_pairs),\n",
    "      \"feature sets dropped due to low entropy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d9e24e2-de7a-4d53-b990-4545861c0cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature set</th>\n",
       "      <th>Mutual information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_1000621000000104-_1000641000000106</td>\n",
       "      <td>0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_1000621000000104-_1000651000000109</td>\n",
       "      <td>0.032518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_1000621000000104-_1000661000000107</td>\n",
       "      <td>0.032527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1000621000000104-_1000671000000100</td>\n",
       "      <td>0.032443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_1000621000000104-_1000681000000103</td>\n",
       "      <td>0.032519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>_1000671000000100-_309646008</td>\n",
       "      <td>0.019237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>_1000671000000100-_313204009</td>\n",
       "      <td>0.021621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>_1000671000000100-_313334002</td>\n",
       "      <td>0.028597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>_1000671000000100-_314138001</td>\n",
       "      <td>0.021124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>_1000671000000100-_314503007</td>\n",
       "      <td>0.026195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Feature set  Mutual information\n",
       "0    _1000621000000104-_1000641000000106            0.032399\n",
       "1    _1000621000000104-_1000651000000109            0.032518\n",
       "2    _1000621000000104-_1000661000000107            0.032527\n",
       "3    _1000621000000104-_1000671000000100            0.032443\n",
       "4    _1000621000000104-_1000681000000103            0.032519\n",
       "..                                   ...                 ...\n",
       "995         _1000671000000100-_309646008            0.019237\n",
       "996         _1000671000000100-_313204009            0.021621\n",
       "997         _1000671000000100-_313334002            0.028597\n",
       "998         _1000671000000100-_314138001            0.021124\n",
       "999         _1000671000000100-_314503007            0.026195\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(entropy_caseness)\n",
    "feature_MI_pair_ORrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca3628-3e07-408c-81b8-2ca72c513c2d",
   "metadata": {},
   "source": [
    "### Entropy and two-way mutual information of triplet-composite feature sets and the caseness variable.\n",
    "The composite feature sets will each be calculated separately to avoid having all the computation in one call, which risks losing everything if it crashes and places heavy demand on RAM.\n",
    "The code below is an obvious extension of the nested FOR LOOPs used to calculate the two-way mutual information of pair-composite feature sets.\n",
    "\n",
    "Note: We still only calculate the mutual information for those feature sets whose entropy at least as great as the outcome variable's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3a219d8-e91f-4b3d-a943-8d34b2d935dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_to_calc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10520/3446657242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_featureSet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf_to_calc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj_featureSet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf_to_calc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Skip the iteration if the same feature set is selected twice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_featureSet\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj_featureSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_to_calc' is not defined"
     ]
    }
   ],
   "source": [
    "for i_featureSet in f_to_calc:\n",
    "    for j_featureSet in f_to_calc:\n",
    "        # Skip the iteration if the same feature set is selected twice.\n",
    "        if i_featureSet == j_featureSet:\n",
    "            continue\n",
    "            \n",
    "        for k_featureSet in f_to_calc:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if len(set([k_featureSet]) & set([i_featureSet, j_featureSet])) > 0:\n",
    "                continue\n",
    "\n",
    "            # Create the feature ID for the pair-composite feature set.\n",
    "            name_var = \"-\".join([i_featureSet, j_featureSet, k_featureSet])\n",
    "\n",
    "            # Update the feature set id table.\n",
    "            featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                    ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                                     'Feature Set 3']] = \\\n",
    "                [name_var, i_featureSet, j_featureSet, k_featureSet]\n",
    "\n",
    "            # Define the pair-composite feature set values.\n",
    "            # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "            # ## sets are 0, and 1 otherwise.\n",
    "            binary_var = \\\n",
    "                pandas.DataFrame(data = {\n",
    "                                          'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                          'j_binary_var' : featureSet_array[j_featureSet] == 0,\n",
    "                                          'k_binary_var' : featureSet_array[k_featureSet] == 0\n",
    "                                         }\n",
    "                                ).all(True)\n",
    "\n",
    "            # Calculate the entropy for the pair-composite feature set.\n",
    "            f_ent = scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "            if f_ent < entropy_caseness:\n",
    "                continue\n",
    "            else:\n",
    "                feature_entropy.loc[len(feature_entropy)] = name_var, f_ent\n",
    "\n",
    "            # Calculate the mutual information for the pair-composite feature set.\n",
    "            feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "                name_var, sklearn.metrics.mutual_info_score(binary_var, caseness_array['CMHD'])\n",
    "\n",
    "feature_entropy.to_csv(\"UNSEEN feature set_entropy_plus triplets.csv\", index = False)\n",
    "feature_mutual_information.to_csv(\"UNSEEN feature set_MutInfo_plus triplets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95814c80-5e38-4c51-b2ea-3c3ca3163f08",
   "metadata": {},
   "source": [
    "### Entropy and two-way mutual information of quadruplet-composite feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1862e5a-a7a4-4a7c-a04d-9eba1e232561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_featureSet in f_to_calc:\n",
    "    for j_featureSet in f_to_calc:\n",
    "        # Skip the iteration if the same feature set is selected twice.\n",
    "        if i_featureSet == j_featureSet:\n",
    "            continue\n",
    "            \n",
    "        for k_featureSet in f_to_calc:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if len(set([k_featureSet]) & set([i_featureSet, j_featureSet])) > 0:\n",
    "                continue\n",
    "                \n",
    "            for l_featureSet in f_to_calc:\n",
    "                # Skip the iteration if the same feature set is selected twice.\n",
    "                if len(set([l_featureSet]) & set([i_featureSet, j_featureSet, k_featureSet])) > 0:\n",
    "                    continue\n",
    "\n",
    "                # Create the feature ID for the pair-composite feature set.\n",
    "                name_var = \"-\".join([i_featureSet, j_featureSet, k_featureSet, l_featureSet])\n",
    "\n",
    "                # Update the feature set id table.\n",
    "                featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                        ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                                         'Feature Set 3',  'Feature Set 4']] = \\\n",
    "                    [name_var, i_featureSet, j_featureSet, k_featureSet, l_featureSet]\n",
    "\n",
    "                # Define the pair-composite feature set values.\n",
    "                # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "                # ## sets are 0, and 1 otherwise.\n",
    "                binary_var = \\\n",
    "                    pandas.DataFrame(data = {\n",
    "                                              'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                              'j_binary_var' : featureSet_array[j_featureSet] == 0,\n",
    "                                              'k_binary_var' : featureSet_array[k_featureSet] == 0,\n",
    "                                              'l_binary_var' : featureSet_array[l_featureSet] == 0\n",
    "                                             }\n",
    "                                    ).all(True)\n",
    "\n",
    "                # Calculate the entropy for the pair-composite feature set.\n",
    "                f_ent = scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "                if f_ent < entropy_caseness:\n",
    "                    continue\n",
    "                else:\n",
    "                    feature_entropy.loc[len(feature_entropy)] = name_var, f_ent\n",
    "\n",
    "                # Calculate the mutual information for the pair-composite feature set.\n",
    "                feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "                    name_var, sklearn.metrics.mutual_info_score(binary_var, caseness_array['CMHD'])\n",
    "\n",
    "feature_entropy.to_csv(\"UNSEEN feature set_entropy_plus quadruplets.csv\", index = False)\n",
    "feature_mutual_information.to_csv(\"UNSEEN feature set_MutInfo_plus quadruplets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f731a15-89cf-434a-babb-3b5387bbe58e",
   "metadata": {},
   "source": [
    "### Entropy and two-way mutual information of quintuplet-composite feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd99ad-5e4c-44bf-98f2-1a8e0d3819f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_featureSet in f_to_calc:\n",
    "    for j_featureSet in f_to_calc:\n",
    "        # Skip the iteration if the same feature set is selected twice.\n",
    "        if i_featureSet == j_featureSet:\n",
    "            continue\n",
    "            \n",
    "        for k_featureSet in f_to_calc:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if len(set([k_featureSet]) & set([i_featureSet, j_featureSet])) > 0:\n",
    "                continue\n",
    "                \n",
    "            for l_featureSet in f_to_calc:\n",
    "                # Skip the iteration if the same feature set is selected twice.\n",
    "                if len(set([l_featureSet]) & set([i_featureSet, j_featureSet, k_featureSet])) > 0:\n",
    "                    continue\n",
    "                \n",
    "                for m_featureSet in f_to_calc:\n",
    "                    # Skip the iteration if the same feature set is selected twice.\n",
    "                    if len(set([m_featureSet]) & set([i_featureSet, j_featureSet, k_featureSet, l_featureSet])) > 0:\n",
    "                        continue\n",
    "\n",
    "                    # Create the feature ID for the pair-composite feature set.\n",
    "                    name_var = \"-\".join([i_featureSet, j_featureSet, k_featureSet, l_featureSet, m_featureSet])\n",
    "\n",
    "                    # Update the feature set id table.\n",
    "                    # ## Note: \n",
    "                    featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                            ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                                             'Feature Set 3',  'Feature Set 4', 'Feature Set 5']] = \\\n",
    "                        [name_var, i_featureSet, j_featureSet, k_featureSet, l_featureSet, m_featureSet]\n",
    "\n",
    "                    # Define the pair-composite feature set values.\n",
    "                    # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "                    # ## sets are 0, and 1 otherwise.\n",
    "                    binary_var = \\\n",
    "                        pandas.DataFrame(data = {\n",
    "                                                  'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                                  'j_binary_var' : featureSet_array[j_featureSet] == 0,\n",
    "                                                  'k_binary_var' : featureSet_array[k_featureSet] == 0,\n",
    "                                                  'l_binary_var' : featureSet_array[l_featureSet] == 0,\n",
    "                                                  'm_binary_var' : featureSet_array[m_featureSet] == 0\n",
    "                                                 }\n",
    "                                        ).all(True)\n",
    "\n",
    "                    # Calculate the entropy for the pair-composite feature set.\n",
    "                    f_ent = scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "                    if f_ent < entropy_caseness:\n",
    "                        continue\n",
    "                    else:\n",
    "                        feature_entropy.loc[len(feature_entropy)] = name_var, f_ent\n",
    "\n",
    "                    # Calculate the mutual information for the pair-composite feature set.\n",
    "                    feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "                        name_var, sklearn.metrics.mutual_info_score(binary_var, caseness_array['CMHD'])\n",
    "\n",
    "feature_entropy.to_csv(\"UNSEEN feature set_entropy_plus quintuplets.csv\", index = False)\n",
    "feature_mutual_information.to_csv(\"UNSEEN feature set_MutInfo_plus quintuplets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a4f9c-e6b0-4d89-af1c-7e569deccf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_entropy['Entropy'].plot.hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c10246-3739-4afc-87de-603caf8109cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mutual_information['Mutual information'].plot.hist(bins = 30)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
