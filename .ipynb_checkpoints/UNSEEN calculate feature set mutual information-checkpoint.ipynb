{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6d5d9a-a6b3-4471-82c7-317ece56bbfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Entropy and Mutual information\n",
    "\n",
    "The purpose of this script is to calculate the mutual information between the caseness variable (i.e. record of a SNOMED CT code for conditions indicative of complex mental health difficulties) and feature sets whose entropy is at least as great as the caseness variable's.\n",
    "\n",
    "This Jupyter notebook runs \"UNSEEN create feature set array.IPYNB\" on which it depends, and \"UNSEEN create caseness array.IPYNB\" on which the feature-set Jupyter notebook depends.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2e91e9e-05e9-466e-b6da-9743e8c41e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47159b04-f348-4084-ad6a-f698384b3979",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Run \"UNSEEN create feature set array.IPYNB\", which runs \"UNSEEN create caseness array.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "00341cd4-abb5-4377-9edc-20832f80f759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ./\"UNSEEN create feature set array.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f085b218-7849-419d-848b-2d42afef00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caseness variable entropy =  0.4 nats\n",
      "Caseness variable scaled entropy =  57.7 %\n",
      "Hit rate (all) = 13.7 %\n",
      "Hit rate (none) = 86.3 %\n",
      "Odds (No CMHD : CMHD) =  6.3 times less likely to have CMHD than to have it.\n"
     ]
    }
   ],
   "source": [
    "%run ./\"UNSEEN create caseness array.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2018413-fe48-40f4-bfec-196b6ff7da3f",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464d5447-b13d-48ca-acaa-c58113119228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate template for storing entropy.\n",
    "feature_entropy_TEMPLATE =\\\n",
    "    pandas.DataFrame(columns = ['Feature set', 'Entropy'])\n",
    "\n",
    "# Instantiate template for storing mutual information.\n",
    "feature_mutual_information_TEMPLATE =\\\n",
    "    pandas.DataFrame(columns = ['Feature set', 'Mutual information'])\n",
    "\n",
    "# Instantiate storage for features that are dropped due to low entropy.\n",
    "f_to_drop_TEMPLATE =\\\n",
    "    pandas.DataFrame(columns = ['Dropped feature set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7319adb-f1af-4489-84b8-ddfee2b637ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate the entropy and two-way mutual information of the feature sets and the caseness.\n",
    "\n",
    "Our focus is mutual information but I check the entropy of features so that I don't calculate the mutual information for any features whose entropy is less than that of the caseness variable. Justification for this action is based on the fact that the mutual information between the caseness variable and any feature will be less than or equal to the lesser entropy of the caseness or feature, i.e. $I(X_{i};CMHD) ≤ min\\{H(X_{i}), H(CMHD)\\}$. We don’t want any feature set that is worse than no feature set (i.e. having only the caseness prevalence to predict a random outcome value) so we don’t bother with any feature set that will lower the possible mutual information. Two-way mutual information* will not be calculated for those features whose entropy is less than the caseness variable's entropy. The dropped variables are indicated in the `f_to_drop` pandas.DataFrame.\n",
    "\n",
    "First, two-way mutual information will be calculated between the caseness variable and individual feature sets. Secondly, two-way mutual information will be calculated between the caseness variable and pair-composites of feature sets. These pair composites are individual feature sets that amalgamate two feature sets into a new binary definition, where values are `0` if both component feature sets are zero and `1` otherwise**. More-complicated encoding is possible, e.g. a different level for every combination of values from each component feature set. Further code extends these feature-set compositions up to quintuplet composites (i.e. amalgamating five feature sets into a single binary variable).\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "__\\*__ _Initially, the plan was to use $k$-way mutual information for $k>2$ but the meaning of these mutual information values is controversial at best. I side with [Krippendorf's assessment](https://sci-hub.wf/10.1080/03081070902993160) , which renders 3-way mutual information interpretable but not any higher-order mutual information statistics (yet?). I decided to stick with two-way mutual information using composite feature sets so that I am comparing the same statistic across individual and composite feature sets._\n",
    "\n",
    "__\\**__ _Other encodings will be trialled at a later date. If a feature set contains more than one feature, then it will be represented in three ways: OR, AND, and multinomial. The OR representation (alternative called the at-least-one representation) is a binary variable with a value of `0` if the component features are all zero, and `1` otherwise. The AND (alternative called the all-present representation) representation is a binary variable with a value of `1` if all component features are one, and `0` otherwise. The multinomial representation is a multinomial variable with values for each of the possible combinations of component features’ values. For example, given a feature set of two features $A=\\{0,1\\}$ and $B=\\{0,1\\}$, their multinomial feature-set representation would be $C=\\{0,1,2,3\\}$, where $C=0=(A=0\\   AND\\   B=0)$, $C=1=(A=0\\   AND\\   B=1)$, $C=2=(A=1\\  AND\\  B=0)$, and $C=3=(A=1\\   AND\\   B=1)$._\n",
    "\n",
    "### Define a function to calculate the mutual information between feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "59330a6f-e936-4e96-b070-18e7116a14d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function that will calculate two-way mutual\n",
    "# information for the features of order m.\n",
    "def featuresetmi(featureArray,\n",
    "                 m = None,\n",
    "                 savelocation = None,\n",
    "                 encoding = None):\n",
    "    # ## Assess argument validty.\n",
    "    #\n",
    "    # Check order of feature set. If not provided,\n",
    "    # default to m = 1.\n",
    "    \n",
    "    # match m:\n",
    "    #     case None:\n",
    "    #         order_int = 1\n",
    "    #         order_label = \"Individuals\"\n",
    "    #         print(\"\\nNo value for m provided.\" +\n",
    "    #               \"\\nDefault value of m = 1 will be used.\")\n",
    "    #     case 1:\n",
    "    #         order_int = m\n",
    "    #         order_label = \"Individuals\"\n",
    "    #     case 2:\n",
    "    #         order_int = m\n",
    "    #         order_label = \"Pairs\"\n",
    "    #     case 3:\n",
    "    #         order_int = m\n",
    "    #         order_label = \"Triplets\"\n",
    "    #     case 4:\n",
    "    #         order_int = m\n",
    "    #         rder_label = \"Quadruplets\"\n",
    "    #     case 5:\n",
    "    #         order_int = m\n",
    "    #         order_label = \"Quintuplets\"\n",
    "    #     case _:\n",
    "    #         print(\"\\n** Error: Integer value between 1\",\n",
    "    #               \"5 not supplied for m.**\\n\")\n",
    "    #         return\n",
    "    \n",
    "    if m == None:\n",
    "        order_int = 1\n",
    "        order_label = \"Individuals\"\n",
    "        print(\"\\nNo value for m provided.\" +\n",
    "              \"\\n...Default value of m = 1 will be used.\")\n",
    "    elif m == 1:\n",
    "        order_int = m\n",
    "        order_label = \"Individuals\"\n",
    "    elif m == 2:\n",
    "        order_int = m\n",
    "        order_label = \"Pairs\"\n",
    "    elif m == 3:\n",
    "        order_int = m\n",
    "        order_label = \"Triplets\"\n",
    "    elif m == 4:\n",
    "        order_int = m\n",
    "        rder_label = \"Quadruplets\"\n",
    "    elif m == 5:\n",
    "        order_int = m\n",
    "        order_label = \"Quintuplets\"\n",
    "    else:\n",
    "        print(\"\\n** Error: Integer value between 1\",\n",
    "              \"5 not supplied for m.**\\n\")\n",
    "        return\n",
    "        \n",
    "    #    \n",
    "    # Check and set save location.\n",
    "    if savelocation == None:\n",
    "        savelocation = \\\n",
    "           (\"Mutual information saves/\"+\\\n",
    "            order_label)\n",
    "        print(\"\\nNo save location provided.\" +\n",
    "              \"\\n...Defaulting to ~/\" + savelocation)    \n",
    "    #\n",
    "    # Check encoding. If not provided, \n",
    "    # default o OR encoding.\n",
    "    \n",
    "    # match encoding:\n",
    "    #     case None:\n",
    "    #         encoding_label = \"ORencoding\"\n",
    "    #         print(\"\\nNo encoding provided.\" +\n",
    "    #               \"\\nDefaulting to '\" + encoding + \"' encoding.\")\n",
    "    #     case \"or\":\n",
    "    #         encoding_label = \"ORencoding\"\n",
    "    #     case \"and\":\n",
    "    #         encoding_label = \"ANDencoding\"\n",
    "    #     case \"multi\":\n",
    "    #         encoding_label = \"MULTIencoding\"\n",
    "    #     case _:\n",
    "    #         print(\"\\n** Error: Encoding value from \",\n",
    "    #               \"{'or', 'and', 'multi'} not provided.**\\n\")\n",
    "    #         return\n",
    "        \n",
    "    if encoding == None:\n",
    "        encoding_label = \"ORencoding\"\n",
    "        print(\"\\nNo encoding provided.\" +\n",
    "              \"\\n...Defaulting to '\" + encoding_label + \"' encoding.\")\n",
    "    elif encoding == \"or\":\n",
    "        encoding_label = \"ORencoding\"\n",
    "    elif encoding == \"and\":\n",
    "        encoding_label = \"ANDencoding\"\n",
    "    elif encoding == \"multi\":\n",
    "        encoding_label = \"MULTIencoding\"\n",
    "    else:\n",
    "        print(\"\\n** Error: Encoding value from \",\n",
    "              \"{'or', 'and', 'multi'} not provided.**\\n\")\n",
    "        return\n",
    "        \n",
    "    \n",
    "    print(\"\\n\\n\\n****************************************\")  \n",
    "    print(    \"Calculating mutual information values...\")\n",
    "    # Define the m-way tuples of features sets as a numpy array. We will loop\n",
    "    # through the rows of this array to create the feature sets.\n",
    "    combins = \\\n",
    "        numpy.asarray(\n",
    "            list(\n",
    "                itertools.combinations(\n",
    "                    featureSet_array.columns[featureSet_array.columns != 'person_id'],\n",
    "                    order_int)\n",
    "                )\n",
    "            )\n",
    "    # Instantiate specific storage for mutual information.\n",
    "    featureSet_MI = \\\n",
    "        pandas.DataFrame(columns = ['Feature set', 'Mutual information'])\n",
    "    # Instantiate batch number.\n",
    "    batch = 0\n",
    "    # Instantiate tally of feature sets that are dropped due to low entropy.\n",
    "    drop_tally = 0\n",
    "    \n",
    "    # ## loop through the feature sets.\n",
    "    for i_fs in range(len(combins)):\n",
    "                \n",
    "        # Define the feature set value.\n",
    "        var_vals = featureSet_array[combins[i_fs]]\n",
    "        binary_var = var_vals.all(True)\n",
    "        \n",
    "        # Calculate the mutual information for the feature set.\n",
    "        f_MI = sklearn.metrics.mutual_info_score(binary_var, caseness_array['CMHD'])\n",
    "\n",
    "        if f_MI < entropy_caseness:\n",
    "            drop_tally += 1\n",
    "            continue\n",
    "        else:\n",
    "            # Name the feature set.\n",
    "            # ...\n",
    "            # Store the name and mutual information value.\n",
    "            featureSet_MI.loc[len(featureSet_MI)] = name_var, f_MI\n",
    "\n",
    "        if len(featureSet_MI) > 9:\n",
    "                # Increment batch.\n",
    "                batch += 1\n",
    "\n",
    "                # Make an interim save of results.\n",
    "                featureSet_MI.to_csv(savelocation +\n",
    "                                  order_label + \"_\" +\n",
    "                                  encoding_label + \"_\" +\n",
    "                                  \"_batch\" + \\\n",
    "                                  str(batch) + \\\n",
    "                                  \".csv\", index = False)\n",
    "                # Instantiate new storage.\n",
    "                featureSet_MI = \\\n",
    "                    pandas.DataFrame(columns = ['Feature set', 'Mutual information'])\n",
    "\n",
    "\n",
    "    # Increment counter.\n",
    "    batch += 1\n",
    "\n",
    "    # Final save.\n",
    "    if len(featureSet_MI) != 0:\n",
    "        featureSet_MI.to_csv(savelocation +\n",
    "                          order_label + \"_\" +\n",
    "                          encoding_label + \"_\" +\n",
    "                          \"_batch\" + \\\n",
    "                          str(batch) + \\\n",
    "                          \".csv\", index = False)\n",
    "\n",
    "    # Feedback messages.\n",
    "    print(\"...\\n\")\n",
    "    print(str(batch), \"batch(es) of feature sets processed.\")\n",
    "    print(str(drop_tally), \"/\",\n",
    "          str(len(combins)),\n",
    "          \"feature sets dropped due to low entropy.\")\n",
    "    print(\"****************************************\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592088df-e7ce-4941-a0ec-63e5b81fead2",
   "metadata": {},
   "source": [
    "### Mutual information of individual feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "53645f7b-94a2-444a-aa32-57b5dc335b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No save location provided.\n",
      "...Defaulting to ~/Mutual information saves/Individuals\n",
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "Calculating mutual information values...\n",
      "...\n",
      "\n",
      "1 batch(es) of feature sets processed.\n",
      "216 / 216 feature sets dropped due to low entropy.\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "featuresetmi(featureArray = featureSet_array,\n",
    "            m = 1,\n",
    "            encoding = \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98143cb2-17a8-4712-a00e-14038338a1a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mutual information of pair-composite feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a74b781a-eede-4b80-9acb-9261cf5598fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No save location provided.\n",
      "...Defaulting to ~/Mutual information saves/Pairs\n",
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "Calculating mutual information values...\n",
      "...\n",
      "\n",
      "1 batch(es) of feature sets processed.\n",
      "23220 / 216 feature sets dropped due to low entropy.\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "featuresetmi(featureArray = featureSet_array,\n",
    "            m = 2,\n",
    "            encoding = \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca3628-3e07-408c-81b8-2ca72c513c2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mutual information of triplet-composite feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ff6afdc2-8ea2-4f62-ac03-267bd53c1e27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No value for m provided.\n",
      "...Default value of m = 1 will be used.\n",
      "\n",
      "No save location provided.\n",
      "...Defaulting to /Mutual information saves/Individuals\n",
      "\n",
      "No encoding provided.\n",
      "...Defaulting to 'ORencoding' encoding.\n",
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "Calculating mutual information values...\n",
      "...\n",
      "\n",
      "1 batch(es) of feature sets processed.\n",
      "60 / 216 feature sets dropped due to low entropy.\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "featuresetmi(featureArray = featureSet_array,\n",
    "            m = 3,\n",
    "            encoding = \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bc15e-ab2a-4bee-912f-c0ee8ea77d41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mutual information of quadruplet-composite feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "04e7ea18-8ff1-42eb-bb73-199194d61e27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No value for m provided.\n",
      "...Default value of m = 1 will be used.\n",
      "\n",
      "No save location provided.\n",
      "...Defaulting to /Mutual information saves/Individuals\n",
      "\n",
      "No encoding provided.\n",
      "...Defaulting to 'ORencoding' encoding.\n",
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "Calculating mutual information values...\n",
      "...\n",
      "\n",
      "1 batch(es) of feature sets processed.\n",
      "60 / 216 feature sets dropped due to low entropy.\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "featuresetmi(featureArray = featureSet_array,\n",
    "            m = 4,\n",
    "            encoding = \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4cf715-1cfe-4868-b484-7780fa0f2323",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mutual information of quintuplet-composite feature sets and the caseness variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d705f84c-91b4-429e-a26b-a7aabf0568fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No value for m provided.\n",
      "...Default value of m = 1 will be used.\n",
      "\n",
      "No save location provided.\n",
      "...Defaulting to /Mutual information saves/Individuals\n",
      "\n",
      "No encoding provided.\n",
      "...Defaulting to 'ORencoding' encoding.\n",
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "Calculating mutual information values...\n",
      "...\n",
      "\n",
      "1 batch(es) of feature sets processed.\n",
      "60 / 216 feature sets dropped due to low entropy.\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "featuresetmi(featureArray = featureSet_array,\n",
    "            m = 5,\n",
    "            encoding = \"or\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc764b31-a1d0-4ede-8d7a-1b09b0dcc03e",
   "metadata": {},
   "source": [
    "# Initial results\n",
    "\n",
    "__\\*__ _Note: these initial results were calculated using a previous version of the script where the mutual information of all feature sets was saved. This approach was dropped in favour of only saving mutual information values for feature sets whose mutual information with the caseness variable is greater than the entropy of the caseness variable._\n",
    "<br/><br/><br/>\n",
    "\n",
    "All individual feature sets score very low for two-way mutual information: all less than 0.05. A $I_{2}=0.05$ represents 7.9% of the theoretical maximal situatons where the feature set either _exactly is_ the caseness variable or _is exactly not_ the variable. The top five individal feature sets (which have $I_{2}≥0.033$) are defined as having at least one recording of the following SNOMED CT codes in their primary-care electronic health records:\n",
    "\n",
    "| SNOMED code | Feature set | Topic | Mutual Information | Scaled mutual information | Odds ratio | P(CMHD given X=1) | P(CMHD given X=0) |\n",
    "| ----------- | ----------- | ----- | ------------------ | ------------------------- | ---------- | ----------------- | ----------------- |\n",
    "| 314530002 | Medication review done | Medication | ~0.055 | 7.9% | 8.5 | 4.1 | 26.8 |\n",
    "| 182888003 | Medication requested  | Medication | ~0.035 | 5.0% | 4.9 | 7.9 | 29.5 |\n",
    "| 1018251000000107 | Serum alanine aminotransferase level (observable entity) | Liver test | ~0.033 | 4.7% | 5.5 | 4.7 | 21.6 |\n",
    "| 1000621000000104 | Serum alkaline phosphatase level | Liver test | ~0.033 | 4.7% | 5.5 | 4.7 | 21.5 |\n",
    "| 1022791000000101 | TSH (thyroid stimulating hormone) level | Endocrine | ~0.033 | 4.7% | 5.0 | 5.4 | 22.5 |\n",
    "\n",
    "The paradoxes of commonly-reported classification statistics are clearly shown. A medication _review_ has the largest odds ratio but the probability of having a record of the caseness variable given that medication was _requested_ is higher. One might propose that a record of a medication request is a better indicator than a record of a medication review, if they prefer the probability statistic over the odds-ratio statistic. But when we look at the probability of the caseness variable given that there is _no_ record of medication being requested, we see that this is also the largest of the top five feature sets! The odds ratio tries to balance these ambiguous probability statistics but it is, therefore, harder to interpret. Note, the odds ratio for a record of a medication _review_ scores better than for a record of medication _request_ because the distinction between the ambiguous probabilities is greater (multiplicatively).\n",
    "\n",
    "The scaled mutual information is simply a percentage measure of how much the caseness variable is described by the feature set (in terms of information). Unlike the odds ratio, it will give the same value whether the odds are multiplicatively greater or less than equal - e.g. $I_{2}$ will be the same for $OR = 4.0$ and $OR = 0.25$  - so it only measures magnitude of association."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
