{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef62a66-4956-4591-b43a-bc3ee30745ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interview feature sets\n",
    "The purpose of this notebook is to create the array of feature sets suggested by the interviews with GPs.\n",
    "\n",
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b044e55d-64e9-43d6-92e9-6a2ca43295cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run 'UNSEEN_helper_functions.ipynb'\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69d2ce-8c42-4879-b232-a480e500679d",
   "metadata": {},
   "source": [
    "## Load codelist CSV files.\n",
    "We used opencodelist.org to define codelists that define the set of SNOMED-CT codes used to identify patients based on various attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c8f34-fdc7-4343-a685-afdbf53f8096",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instaniate BigQuery client.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set folder location.\n",
    "folder_loc = os.path.dirname(os.path.abspath(\"UNSEEN create clinician feature sets.ipynb\"))\n",
    "folder = folder_loc + '/codelists/'\n",
    "\n",
    "# Clinical codes of interest.\n",
    "codes_to_query_DNA = pandas.read_csv(folder + \"ciaranmci-did-not-attend-098119da.csv\")\n",
    "codes_to_query_suicidal = pandas.read_csv(folder + \"ciaranmci/suicidal/5eaa56c5/.csv\")\n",
    "codes_to_query_historyOfOrCurrentAddiction = pandas.read_csv(folder + \"ciaranmci/history-of-or-current-addiction/5bf796cf/.csv\")\n",
    "codes_to_query_drugMisuse = pandas.read_csv(folder + \"ciaranmci/drug-misuse/3acfe3b8/.csv\")\n",
    "codes_to_query_alcoholMisuse = pandas.read_csv(folder + \"ciaranmci/alcohol-misuse/53df56ed/.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfdf4e2-64c4-40a3-965d-14632520023f",
   "metadata": {},
   "source": [
    "## Load prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bff67f-edf7-462b-943b-a6909b113e94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if 'caseness_array' not in globals():\n",
    "    print(\"not here\")\n",
    "    %run ./\"UNSEEN_create_caseness_variables.ipynb\"\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf4787-ac83-477f-a2d1-e6cf91669f26",
   "metadata": {},
   "source": [
    "## Query database for base feature sets\n",
    "The code below returns `fs_interview` that contains the base feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9401d-9ee0-489e-984a-593c21dc8b00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_CTEs_top = \"\"\"\n",
    "WITH\n",
    "# The first CTE will specify the 'spine' of the data table by selecting the unique list of person IDs.\n",
    "tbl_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,year_of_birth\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".person\n",
    "    # Limiting to age range 18-70.\n",
    "    WHERE\n",
    "        (EXTRACT(YEAR FROM CURRENT_DATE()) - year_of_birth) BETWEEN 18 AND 70\n",
    ")\n",
    "\n",
    "# The following CTEs extract each clinical codelist into a SQL table before querying the person_ID \n",
    "# associated with the clinical codes.\n",
    "#\n",
    "\"\"\"\n",
    "\n",
    "sql_CTEs_body = \\\n",
    "\"\"\"\n",
    "#  ## Count of appointments in the previous year.\n",
    ",tbl_countAppointmentsPreviousYear_persons AS ( \n",
    "    SELECT \n",
    "        DISTINCT person_id\n",
    "        ,COUNT( DISTINCT EXTRACT(DATE FROM datestart) ) AS countAppointmentsPreviousYear\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srappointment\n",
    "    WHERE\n",
    "        DATE_DIFF(CURRENT_DATE(), datestart, YEAR) <= 1\n",
    "    GROUP BY\n",
    "        person_id\n",
    "    ORDER BY\n",
    "        person_id\n",
    ")\n",
    "# ## Median annual count of appointments.\n",
    ",tbl_annualCountOfAppointments AS (\n",
    "    SELECT \n",
    "        DISTINCT person_id\n",
    "        ,EXTRACT(YEAR FROM datestart) AS year_appointment\n",
    "        ,COUNT( DISTINCT EXTRACT(DATE FROM datestart) ) AS countAppointmentsPerYear\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srappointment\n",
    "    GROUP BY\n",
    "        person_id\n",
    "        ,year_appointment\n",
    "    ORDER BY\n",
    "        person_id\n",
    "        ,year_appointment\n",
    ")\n",
    ",tbl_medianAnnualCountAppointments_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,PERCENTILE_DISC(countAppointmentsPerYear, 0.5) OVER(PARTITION BY person_id) AS medianAnnualCountAppointments\n",
    "    FROM\n",
    "        tbl_annualCountOfAppointments\n",
    "    ORDER BY\n",
    "        person_id\n",
    ")\n",
    "#  ## Count of Did-Not-Attend (DNA) in the previous year.\n",
    ",tbl_DNAcodes AS ( \n",
    "    SELECT\n",
    "        snomedcode\n",
    "    FROM\n",
    "        UNNEST([\n",
    "                '\"\"\" + '\\', \\''.join(map(str, codes_to_query_DNA[\"code\"].tolist())) + \"\"\"'\n",
    "                ]) AS snomedcode\n",
    ")\n",
    ",tbl_countDNAsPreviousYear_persons AS ( \n",
    "    SELECT \n",
    "      DISTINCT a.person_id\n",
    "     ,COUNT(person_id) AS countDNAsPreviousYear\n",
    "    FROM\n",
    "      \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_DNAcodes\n",
    "    WHERE\n",
    "      a.snomedcode IN (tbl_DNAcodes.snomedcode)\n",
    "      AND DATE_DIFF(CURRENT_DATE(), dateevent, YEAR) <= 1\n",
    "    GROUP BY\n",
    "        person_id\n",
    ")\n",
    "# ## Median annual count of Did-Not-Attend (DNA).\n",
    ",tbl_annualCountOfDNAs AS ( \n",
    "    SELECT \n",
    "        DISTINCT a.person_id\n",
    "        ,EXTRACT(YEAR FROM dateevent) AS year_DNA\n",
    "        ,COUNT( DISTINCT EXTRACT(DATE FROM dateevent) ) AS countDNAsPerYear\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_DNAcodes\n",
    "    WHERE\n",
    "        a.snomedcode IN (tbl_DNAcodes.snomedcode)\n",
    "    GROUP BY\n",
    "        person_id\n",
    "        ,year_DNA\n",
    ")\n",
    ",tbl_medianAnnualCountDNAs_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT tbl_annualCountOfDNAs.person_id\n",
    "        ,PERCENTILE_DISC(countDNAsPerYear, 0.5) OVER(PARTITION BY person_id) AS medianAnnualCountDNAs\n",
    "    FROM\n",
    "        tbl_annualCountOfDNAs\n",
    "    ORDER BY\n",
    "        person_id\n",
    ")\n",
    "# ## Ratio of annual counts of Did-Not-Attend (DNA) to appointment, in the previous year.\n",
    ",tbl_ratioDNAtoAppointmentPreviousYear_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT tbl_countDNAsPreviousYear_persons.person_id\n",
    "        ,(countDNAsPreviousYear / countAppointmentsPreviousYear) AS ratioDNAtoAppointmentPreviousYear\n",
    "    FROM\n",
    "        tbl_countDNAsPreviousYear_persons\n",
    "    LEFT OUTER JOIN tbl_countAppointmentsPreviousYear_persons ON tbl_countDNAsPreviousYear_persons.person_id = tbl_countAppointmentsPreviousYear_persons.person_id\n",
    "        \n",
    ")\n",
    "# ## Median annual ratio of DNA to appointments\n",
    ",tbl_medianAnnualRatioDNAtoAppointment_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT tbl_annualCountOfDNAs.person_id\n",
    "        ,PERCENTILE_DISC( (countDNAsPerYear / countAppointmentsPerYear), 0.5) OVER(PARTITION BY tbl_annualCountOfDNAs.person_id) AS medianAnnualRatioDNAtoAppointment\n",
    "    FROM\n",
    "        tbl_annualCountOfDNAs\n",
    "    LEFT OUTER JOIN\n",
    "        tbl_annualCountOfAppointments\n",
    "        ON\n",
    "        (\n",
    "        tbl_annualCountOfDNAs.person_id = tbl_annualCountOfAppointments.person_id\n",
    "        AND tbl_annualCountOfDNAs.year_DNA = tbl_annualCountOfAppointments.year_appointment\n",
    "        )\n",
    ")\n",
    "# ## Trafficked person.\n",
    ",tbl_trafficked_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "        snomedcode IN ('734998001')\n",
    ")\n",
    "# ## Tortured person.\n",
    ",tbl_tortured_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "        snomedcode IN ('248006006', '95318007')\n",
    "#  ## Suicidal\n",
    ",tbl_suicidal AS ( \n",
    "    SELECT\n",
    "        snomedcode\n",
    "    FROM\n",
    "        UNNEST([\n",
    "                '\"\"\" + '\\', \\''.join(map(str, codes_to_query_suicidal[\"code\"].tolist())) + \"\"\"'\n",
    "                ]) AS snomedcode\n",
    ")\n",
    ",tbl_suicidal_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,a.snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_suicidal\n",
    "    WHERE\n",
    "        a.snomedcode IN (tbl_suicidal.snomedcode)\n",
    ")\n",
    "# ## Obsessive-compulsive disorder.\n",
    ",tbl_OCD_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "        snomedcode IN ('191736004')\n",
    ")\n",
    "# ## Non-native English speaker.\n",
    ",tbl_nonNativeEnglishSpeaker_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "        snomedcode IN ('161148002', '1047281000000107')\n",
    ")\n",
    "# ## Hoarder.\n",
    ",tbl_hoarder_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "        snomedcode IN ('248025009', '247968005')\n",
    ")\n",
    "#  ## History of or current addiction.\n",
    ",tbl_historyOfOrCurrentAddiction AS ( \n",
    "    SELECT\n",
    "        snomedcode\n",
    "    FROM\n",
    "        UNNEST([\n",
    "                '\"\"\" + '\\', \\''.join(map(str, codes_to_query_historyOfOrCurrentAddiction[\"code\"].tolist())) + \"\"\"'\n",
    "                ]) AS snomedcode\n",
    ")\n",
    ",tbl_historyOfOrCurrentAddiction_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,a.snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_historyOfOrCurrentAddiction\n",
    "    WHERE\n",
    "        a.snomedcode IN (tbl_historyOfOrCurrentAddiction.snomedcode)\n",
    ")\n",
    "# ## Family history of psychosis.\n",
    ",tbl_familyHistoryOfPsychosis_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "       a.snomedcode IN ('266969002', '429399002', '293721000000105', '293731000000107')\n",
    ")\n",
    "# ## Family history of alcoholism.\n",
    ",tbl_familyHistoryOfAlcoholism_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "       a.snomedcode IN ('266890009', '293161000000103')\n",
    ")\n",
    "# ## Extreme self-neglect.\n",
    ",tbl_extremeSelfNeglect_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "       a.snomedcode IN ('277850002', '439124004', '735939003')\n",
    ")\n",
    "#  ## Drug misuse\n",
    ",tbl_drugMisuse AS ( \n",
    "    SELECT\n",
    "        snomedcode\n",
    "    FROM\n",
    "        UNNEST([\n",
    "                '\"\"\" + '\\', \\''.join(map(str, codes_to_query_drugMisuse[\"code\"].tolist())) + \"\"\"'\n",
    "                ]) AS snomedcode\n",
    ")\n",
    ",tbl_drugMisuse_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,a.snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_drugMisuse\n",
    "    WHERE\n",
    "        a.snomedcode IN (tbl_drugMisuse.snomedcode)\n",
    ")\n",
    "# ## Body dysmorphic disorder.\n",
    ",tbl_bodyDysmorphicDisorder_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode\n",
    "    WHERE\n",
    "       a.snomedcode IN ('83482000')\n",
    ")\n",
    "#  ## Alcohol misuse.\n",
    ",tbl_alcoholMisuse AS ( \n",
    "    SELECT\n",
    "        snomedcode\n",
    "    FROM\n",
    "        UNNEST([\n",
    "                '\"\"\" + '\\', \\''.join(map(str, codes_to_query_alcoholMisuse[\"code\"].tolist())) + \"\"\"'\n",
    "                ]) AS snomedcode\n",
    ")\n",
    ",tbl_alcoholMisuse_persons AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,a.snomedcode\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_alcoholMisuse\n",
    "    WHERE\n",
    "        a.snomedcode IN (tbl_alcoholMisuse.snomedcode)\n",
    ")\n",
    "\n",
    "\n",
    "#######################################################\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sql_final_select = \\\n",
    "\"\"\"\n",
    "# Finally, we use the above CTEs to define a table with one row per patient and one column for each\n",
    "# feature set. The feature-set columns are populated by interger values with '1' indicating that the\n",
    "# feature set is satisfied and '0' indicating otherwise.\n",
    "SELECT\n",
    "    DISTINCT tbl_persons.person_id\n",
    "    ,countAppointmentsPreviousYear\n",
    "    ,medianAnnualCountAppointments\n",
    "    ,countDNAsPreviousYear\n",
    "    ,medianAnnualCountDNAs\n",
    "    ,ratioDNAtoAppointmentPreviousYear\n",
    "    ,medianAnnualRatioDNAtoAppointment\n",
    "    ,CASE WHEN tbl_trafficked_persons.person_id IS NULL THEN 0 ELSE 1 END AS trafficked\n",
    "    ,CASE WHEN tbl_tortured_persons.person_id IS NULL THEN 0 ELSE 1 END AS tortured\n",
    "    ,CASE WHEN tbl_suicidal_persons.person_id IS NULL THEN 0 ELSE 1 END AS suicidal\n",
    "    ,CASE WHEN tbl_OCD_persons.person_id IS NULL THEN 0 ELSE 1 END AS OCD\n",
    "    ,CASE WHEN tbl_nonNativeEnglishSpeaker_persons.person_id IS NULL THEN 0 ELSE 1 END AS nonNativeEnglishSpeaker\n",
    "    ,CASE WHEN tbl_hoarder_persons.person_id IS NULL THEN 0 ELSE 1 END AS hoarder\n",
    "    ,CASE WHEN tbl_historyOfOrCurrentAddiction_persons.person_id IS NULL THEN 0 ELSE 1 END AS historyOfOrCurrentAddiction\n",
    "    ,CASE WHEN tbl_familyHistoryOfPsychosis_persons.person_id IS NULL THEN 0 ELSE 1 END AS familyHistoryOfPsychosis\n",
    "    ,CASE WHEN tbl_familyHistoryOfAlcoholism_persons.person_id IS NULL THEN 0 ELSE 1 END AS familyHistoryOfAlcoholism\n",
    "    ,CASE WHEN tbl_extremeSelfNeglect_persons.person_id IS NULL THEN 0 ELSE 1 END AS extremeSelfNeglect\n",
    "    ,CASE WHEN tbl_drugMisuse_persons.person_id IS NULL THEN 0 ELSE 1 END AS drugMisuse\n",
    "    ,CASE WHEN tbl_bodyDysmorphicDisorder_persons.person_id IS NULL THEN 0 ELSE 1 END AS bodyDysmorphicDisorder\n",
    "    ,CASE WHEN tbl_alcoholMisuse_persons.person_id IS NULL THEN 0 ELSE 1 END AS alcoholMisuse\n",
    "    \n",
    "FROM tbl_persons\n",
    "LEFT OUTER JOIN tbl_countAppointmentsPreviousYear_persons ON tbl_persons.person_id = tbl_countAppointmentsPreviousYear_persons.person_id\n",
    "LEFT OUTER JOIN tbl_medianAnnualCountAppointments_persons ON tbl_persons.person_id = tbl_medianAnnualCountAppointments_persons.person_id\n",
    "LEFT OUTER JOIN tbl_countDNAsPreviousYear_persons ON tbl_persons.person_id = tbl_countDNAsPreviousYear_persons.person_id\n",
    "LEFT OUTER JOIN tbl_medianAnnualCountDNAs_persons ON tbl_persons.person_id = tbl_medianAnnualCountDNAs_persons.person_id\n",
    "LEFT OUTER JOIN tbl_ratioDNAtoAppointmentPreviousYear_persons ON tbl_persons.person_id = tbl_ratioDNAtoAppointmentPreviousYear_persons.person_id\n",
    "LEFT OUTER JOIN tbl_medianAnnualRatioDNAtoAppointment_persons ON tbl_persons.person_id = tbl_medianAnnualRatioDNAtoAppointment_persons.person_id\n",
    "LEFT OUTER JOIN tbl_trafficked_persons ON tbl_persons.person_id = tbl_trafficked_persons.person_id\n",
    "LEFT OUTER JOIN tbl_tortured_persons ON tbl_persons.person_id = tbl_tortured_persons.person_id\n",
    "LEFT OUTER JOIN tbl_suicidal_persons ON tbl_persons.person_id = tbl_suicidal_persons.person_id\n",
    "LEFT OUTER JOIN tbl_OCD_persons ON tbl_persons.person_id = tbl_OCD_persons.person_id\n",
    "LEFT OUTER JOIN tbl_nonNativeEnglishSpeaker_persons ON tbl_persons.person_id = tbl_nonNativeEnglishSpeaker_persons.person_id\n",
    "LEFT OUTER JOIN tbl_hoarder_persons ON tbl_persons.person_id = tbl_hoarder_persons.person_id\n",
    "LEFT OUTER JOIN tbl_historyOfOrCurrentAddiction_persons ON tbl_persons.person_id = tbl_historyOfOrCurrentAddiction_persons.person_id\n",
    "LEFT OUTER JOIN tbl_familyHistoryOfPsychosis_persons ON tbl_persons.person_id = tbl_familyHistoryOfPsychosis_persons.person_id\n",
    "LEFT OUTER JOIN tbl_familyHistoryOfAlcoholism_persons ON tbl_persons.person_id = tbl_familyHistoryOfAlcoholism_persons.person_id\n",
    "LEFT OUTER JOIN tbl_extremeSelfNeglect_persons ON tbl_persons.person_id = tbl_extremeSelfNeglect_persons.person_id\n",
    "LEFT OUTER JOIN tbl_drugMisuse_persons ON tbl_persons.person_id = tbl_drugMisuse_persons.person_id\n",
    "LEFT OUTER JOIN tbl_bodyDysmorphicDisorder_persons ON tbl_persons.person_id = tbl_bodyDysmorphicDisorder_persons.person_id\n",
    "LEFT OUTER JOIN tbl_alcoholMisuse_persons ON tbl_persons.person_id = tbl_alcoholMisuse_persons.person_id\n",
    "\n",
    "ORDER BY tbl_persons.person_id\n",
    "\"\"\"\n",
    "\n",
    "fs_interview = client.query(sql_CTEs_top + sql_CTEs_body + sql_final_select).to_dataframe().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b3461-4cd0-4dfb-874b-7239d191ad59",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Entropy-based feature sets potentially indicative of \"chaotic life\"\n",
    "\n",
    "The data from BigQuery needs to be appointments and DNAs tallied in three-month blocks, per person. Specifically, I use BigQuery's built-in `QUARTER()` function for which Q1 = Jan-Mar, Q2 = Apr-Jun, etc.  The query will only return data for quarters in which there was an appointment or a DNA. Each patient's data will be processed in Python to fill in the missing quarters' counts with 0 before calculating the values of the entropy-based feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29379469-2835-40a6-abf7-78ff56dfe7f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_CTEs_body = \\\n",
    "\"\"\"\n",
    "WITH\n",
    "#  ## Count of appointments, per quarter.\n",
    "tbl_countAppointmentsPerQuarter AS (\n",
    "    SELECT\n",
    "        DISTINCT person_id\n",
    "        ,EXTRACT(YEAR FROM datestart) AS year_appointment\n",
    "        ,EXTRACT(QUARTER FROM datestart) AS quarter_appointment\n",
    "        ,COUNT(DISTINCT datestart) AS countAppointmentsPerQuarter\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srappointment\n",
    "    GROUP BY\n",
    "         person_id\n",
    "        ,year_appointment\n",
    "        ,quarter_appointment\n",
    "\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "sql_final_select = \\\n",
    "\"\"\"\n",
    "SELECT\n",
    "    person_id\n",
    "    ,year_appointment\n",
    "    ,quarter_appointment\n",
    "    ,countAppointmentsPerQuarter\n",
    "FROM\n",
    "    tbl_countAppointmentsPerQuarter\n",
    "ORDER BY\n",
    "    person_id\n",
    "    ,year_appointment\n",
    "    ,quarter_appointment\n",
    "\"\"\"\n",
    "\n",
    "bq_countAppointmentsPerQuarter = client.query(sql_CTEs_body + sql_final_select).to_dataframe().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007263b2-6816-4de9-889b-8d194cb3c9fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_CTEs_body = \\\n",
    "\"\"\"\n",
    "WITH\n",
    "#  ## Count of did-not-attend (DNA), per quarter.\n",
    "tbl_DNAcodes AS ( \n",
    "    SELECT\n",
    "        snomedcode\n",
    "    FROM\n",
    "        UNNEST([\n",
    "                '\"\"\" + '\\', \\''.join(map(str, codes_to_query_DNA[\"code\"].tolist())) + \"\"\"'\n",
    "                ]) AS snomedcode\n",
    ")\n",
    ",tbl_countDNAsPerQuarter AS ( \n",
    "    SELECT \n",
    "        DISTINCT a.person_id\n",
    "        ,EXTRACT(YEAR FROM dateevent) AS year_DNA\n",
    "        ,EXTRACT(QUARTER FROM dateevent) AS quarter_DNA\n",
    "        ,COUNT( DISTINCT EXTRACT(DATE FROM dateevent) ) AS countDNAsPerQuarter\n",
    "    FROM\n",
    "        \"\"\" + server_id + \"\"\".\"\"\" + database_id + \"\"\".tbl_srcode AS a, tbl_DNAcodes\n",
    "    WHERE\n",
    "        a.snomedcode IN (tbl_DNAcodes.snomedcode)\n",
    "    GROUP BY\n",
    "        person_id\n",
    "        ,year_DNA\n",
    "        ,quarter_DNA\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "sql_final_select = \\\n",
    "\"\"\"\n",
    "SELECT\n",
    "    person_id\n",
    "    ,year_DNA\n",
    "    ,quarter_DNA\n",
    "    ,countDNAsPerQuarter\n",
    "FROM\n",
    "    tbl_countDNAsPerQuarter\n",
    "ORDER BY\n",
    "    person_id\n",
    "    ,year_DNA\n",
    "    ,quarter_DNA\n",
    "\"\"\"\n",
    "\n",
    "bq_countDNAsPerQuarter = client.query(sql_CTEs_body + sql_final_select).to_dataframe().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fdefe-1243-43b2-958d-9aef0f9828a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set storage.\n",
    "ls_entropyBased_fs_appts = [['activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "ls_entropyBased_fs_DNAs = [['activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "ls_pids = list(set(numpy.concatenate((bq_countAppointmentsPerQuarter.head(100).person_id.unique(), bq_countDNAsPerQuarter.person_id.unique()))))\n",
    "ls_pids.sort()\n",
    "\n",
    "t1 = time.time()\n",
    "for pid in ls_pids:\n",
    "    # Extract this particular patient's range of active years.\n",
    "    pt_years = \\\n",
    "        bq_countAppointmentsPerQuarter.loc[bq_countAppointmentsPerQuarter.person_id == pid, 'year_appointment'].append(\n",
    "         bq_countDNAsPerQuarter.loc[bq_countDNAsPerQuarter.person_id == pid, 'year_DNA'])\n",
    "    \n",
    "    pt_years_lsrange =  pandas.DataFrame(\n",
    "        data = { 'year' : list( range( min(pt_years), max(pt_years) ) ) }\n",
    "        )\n",
    "    # Create a timeline of years and quarters for this particular patient.\n",
    "    pt_quarters = pandas.DataFrame( data = {'qtr': [1,2,3,4]} )\n",
    "    pt_timeline = pt_years_lsrange.merge(pt_quarters, how = 'cross')\n",
    "    \n",
    "    # Join the patient's actual count of appointments-per-quarter-per-year to their timeline.\n",
    "    pt_appts = bq_countAppointmentsPerQuarter.loc[bq_countAppointmentsPerQuarter.person_id == pid, :]\n",
    "    pt_timeline_appts = \\\n",
    "        pandas.merge(pt_timeline, pt_appts, how = 'left',\n",
    "                     left_on = ['year', 'qtr'],\n",
    "                     right_on = ['year_appointment',\n",
    "                                 'quarter_appointment']).loc[:,'countAppointmentsPerQuarter'].fillna(0).astype(int)\n",
    "    \n",
    "    # Repeat for did-not-attend events.\n",
    "    pt_DNAs = bq_countDNAsPerQuarter.loc[bq_countDNAsPerQuarter.person_id == pid, :]\n",
    "    pt_timeline_DNAs = \\\n",
    "        pandas.merge(pt_timeline, pt_DNAs, how = 'left',\n",
    "                     left_on = ['year', 'qtr'],\n",
    "                     right_on = ['year_DNA',\n",
    "                                 'quarter_DNA']).loc[:,'countDNAsPerQuarter'].fillna(0).astype(int)\n",
    "\n",
    "    # Create the entropy-based feature sets.\n",
    "    pt_entropyStats_appts = chaoticlifeentropyfs(pt_timeline_appts)\n",
    "    ls_entropyBased_fs_appts.append(pt_entropyStats_appts)\n",
    "    pt_entropyStats_DNAs = chaoticlifeentropyfs(pt_timeline_DNAs)\n",
    "    ls_entropyBased_fs_DNAs.append(pt_entropyStats_DNAs)\n",
    "\n",
    "print(f'It took {time.time() - t1} to process.')\n",
    "# Convert the nested list into a pandas.DataFrame.\n",
    "entropyBasedFS = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "entropyBasedFS.insert(0, 'person_id', ls_pids)\n",
    "\n",
    "entropyBasedFS_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "entropyBasedFS_DNAs.insert(0, 'person_id', ls_pids)\n",
    "\n",
    "entropyBasedFS = entropyBasedFS.merge(entropyBasedFS_DNAs\n",
    "                                      ,how = 'outer'\n",
    "                                      ,on = 'person_id')\n",
    "entropyBasedFS.set_axis(\n",
    "    ['person_id'\n",
    "     ,'activeInformationAppts'\n",
    "     ,'entropyRateAppts'\n",
    "     ,'spectralEntropyAppts'\n",
    "     ,'sampleEntroptAppts'\n",
    "     ,'eoeAppts'\n",
    "     ,'averageEntropyAppts'\n",
    "     ,'bubbleEntropyAppts'\n",
    "     ,'activeInformationDNAs'\n",
    "     ,'entropyRateDNAs'\n",
    "     ,'spectralEntropyDNAs'\n",
    "     ,'sampleEntropyDNAs'\n",
    "     ,'eoeDNAs'\n",
    "     ,'averageEntropyDNAs'\n",
    "     ,'bubbleEntropyDNAs'\n",
    "    ]\n",
    "    ,axis = 1\n",
    "    ,inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a33bec-1a45-41b8-92b8-9bd11cf12437",
   "metadata": {},
   "outputs": [],
   "source": [
    "34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb7559d-1c96-4c81-a33e-b36a3c4dabef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Filter feature sets not within bounds\n",
       "\n",
       "All feature sets must have a prevalence (or count) between the prevalence (or count) bounds defined in `UNSEEN_feature_sets_prevalence_bounds.ipynb`,\n",
       "i.e. a feature set's count must satisfy:\n",
       "- $18,950\\le$ $count\\ of\\ patients_{feature\\ set_{i}}$ $\\le37,890$, for 'Possible caseness'\n",
       "- $770\\le$ $count\\ of\\ patients_{feature\\ set_{i}}$ $\\le1,530$, for 'Definite caseness'\n",
       "- $19,710\\le$ $count\\ of\\ patients_{feature\\ set_{i}}$ $\\le39,430$, for 'Multinomial caseness'\n",
       "- $770\\le$ $count\\ of\\ patients_{feature\\ set_{i}}$ $\\le1,530$, for 'Possible-vs-Definite caseness'\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display message.\n",
    "display(\n",
    "    Markdown(\n",
    "f\"\"\"\n",
    "## Filter feature sets not within bounds\n",
    "\n",
    "All feature sets must have a prevalence (or count) between the prevalence (or count) bounds defined in `UNSEEN_feature_sets_prevalence_bounds.ipynb`,\n",
    "i.e. a feature set's count must satisfy:\n",
    "- ${int(possibleCaseness_count_LB):,}\\le$ $count\\ of\\ patients_{{feature\\ set_{{i}}}}$ $\\le{int(possibleCaseness_count_UB):,}$, for 'Possible caseness'\n",
    "- ${int(definiteCaseness_count_LB):,}\\le$ $count\\ of\\ patients_{{feature\\ set_{{i}}}}$ $\\le{int(definiteCaseness_count_UB):,}$, for 'Definite caseness'\n",
    "- ${int(multinomialCaseness_count_LB):,}\\le$ $count\\ of\\ patients_{{feature\\ set_{{i}}}}$ $\\le{int(multinomialCaseness_count_UB):,}$, for 'Multinomial caseness'\n",
    "- ${int(possdefCaseness_count_LB):,}\\le$ $count\\ of\\ patients_{{feature\\ set_{{i}}}}$ $\\le{int(possdefCaseness_count_UB):,}$, for 'Possible-vs-Definite caseness'\n",
    "\"\"\"\n",
    "       )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9921532f-455c-44e3-8818-3b779d015100",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Filtering complete for 'Possible caseness'...\n",
      "\t 1  feature sets remain.\n",
      "\t 4  feature sets removed, in total.\n",
      "\t 4  feature sets removed because of low prevalence.\n",
      "\t 0  feature sets removed because of high prevalence.\n",
      "\n",
      "The final list of feature sets from this source is:\n",
      " ['sleepDisturbance']\n",
      "\n",
      " Filtering complete for 'Definite caseness'...\n",
      "\t 0  feature sets remain.\n",
      "\t 5  feature sets removed, in total.\n",
      "\t 1  feature sets removed because of low prevalence.\n",
      "\t 4  feature sets removed because of high prevalence.\n",
      "\n",
      "The final list of feature sets from this source is:\n",
      " []\n",
      "\n",
      " Filtering complete for 'Multi caseness'...\n",
      "\t 1  feature sets remain.\n",
      "\t 4  feature sets removed, in total.\n",
      "\t 4  feature sets removed because of low prevalence.\n",
      "\t 0  feature sets removed because of high prevalence.\n",
      "\n",
      "The final list of feature sets from this source is:\n",
      " ['sleepDisturbance']\n",
      "\n",
      " Filtering complete for 'Possible-vs-Definite caseness'...\n",
      "\t 0  feature sets remain.\n",
      "\t 5  feature sets removed, in total.\n",
      "\t 1  feature sets removed because of low prevalence.\n",
      "\t 4  feature sets removed because of high prevalence.\n",
      "\n",
      "The final list of feature sets from this source is:\n",
      " []\n",
      "Stored 'fs_literature_filteredPossible' (DataFrame)\n",
      "Stored 'fs_literature_filteredDefinite' (DataFrame)\n",
      "Stored 'fs_literature_filteredMulti' (DataFrame)\n",
      "Stored 'fs_literature_filteredPossDef' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "fs_interview_filteredPossible = boundaryfilter(my_featureSet_array = fs_interview, caseness = 'possible', verbose = True)[0]\n",
    "print(\"\\nThe final list of feature sets from this source is:\\n\", fs_interview_filteredPossible.columns.values[1:])\n",
    "fs_interview_filteredDefinite = boundaryfilter(my_featureSet_array = fs_interview, caseness = 'definite', verbose = True)[0]\n",
    "print(\"\\nThe final list of feature sets from this source is:\\n\", fs_interview_filteredDefinite.columns.values[1:])\n",
    "fs_interview_filteredMulti = boundaryfilter(my_featureSet_array = fs_interview, caseness = 'multi', verbose = True)[0]\n",
    "print(\"\\nThe final list of feature sets from this source is:\\n\", fs_interview_filteredMulti.columns.values[1:])\n",
    "fs_interview_filteredPossDef = boundaryfilter(my_featureSet_array = fs_interview, caseness = 'possdef', verbose = True)[0]\n",
    "print(\"\\nThe final list of feature sets from this source is:\\n\", fs_interview_filteredPossDef.columns.values[1:])\n",
    "\n",
    "\n",
    "\n",
    "# Store clinician feature sets for use in other notebooks.\n",
    "%store fs_interview_filteredPossible fs_interview_filteredDefinite fs_interview_filteredMulti fs_interview_filteredPossDef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5539d6-31f2-4642-87d4-43585448ba2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ---------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
