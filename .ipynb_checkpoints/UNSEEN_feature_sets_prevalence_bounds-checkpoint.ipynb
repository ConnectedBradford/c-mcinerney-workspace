{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedf8e59-41ca-4821-b27f-c02d777204ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Filtering feature sets based on prevalence\n",
    "\n",
    "The intended use of the feature sets is to support clinicians in identifying patients with complex mental health difficulties so that resources can be appropriately delivered. Without information like feature sets, the clinicianâ€™s expected accuracy in identifying patients with complex mental difficulties is $50\\%$ - a coin toss. Alternatively, with no other information, one could assume everyone has complex mental health difficulties or no one does. A balance must be struck between these extremes to facilitate optimal and appropriate use of healthcare resources that maximises benefit for the unidentified patients in need. Some boundaries can be defined for this purpose.\n",
    "\n",
    "We will only consider feature sets whose prevalence is between $0.7$- and $1.4$-times the prevalence of the caseness variable. This is based on our simulations that suggest this prevalence range is needed for a feature set to be capable of a normalised mutual information $\\ge0.8$ (in the best-case scenario across a range of caseness prevalence values; `Supplementary material xNMIsimx`). In middle- and worst-case scenarios, it would not be possible for feature sets to satisfy the $\\ge0.8$ threshold for normalised mutual information. Further explanations are in `Supplementary material xNMIsimx`). Initially, we prefer to our high but informative threshold over a lower and less-informative threshold because it maintains the caseness variable as the target reference rather than the candidate feature sets.\n",
    "\n",
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a333e4fd-4a2b-4eba-ba00-5f4471722e68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run 'UNSEEN_helper_functions.ipynb'\n",
    "# Refresh stored variables.\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583b200-ebf6-4957-ac2d-39c49096a851",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9c63fe-d1a0-4f80-9393-7c28e28883cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the variables related to the caseness variables exist.\n",
    "if 'definiteCaseness_count' not in globals():\n",
    "    %run ./\"UNSEEN_create_caseness_variables.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff9d8ae-9cf2-4470-bcf2-3dad5af5b2ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Running our script to calculate the prevalence of our caseness variable shows that:\n",
       "- the prevalence of 'Possible caseness' is $0.123\\%$, which equates to a redacted and rounded count of $860$\n",
       "- the prevalence of 'Definite caseness' is $0.009\\%$, which equates to a redacted and rounded count of $60$\n",
       "\n",
       "Our simulations suggested upper- and lower-bound scaling factors of $0.7$ and $1.4$ to ensure  feature sets have at least $80\\%$ normalised mutual information\n",
       "with the caseness variables, in the best-case scenario.\n",
       "\n",
       "These data mean that:\n",
       "- for the 'Possible caseness' variable, we will only consider feature sets that are present in at least $600$\n",
       "patients' records and no more than $1,200$ patients' records.\n",
       "- for the 'Definite caseness' variable, we will only consider feature sets that are present in at least $40$\n",
       "patients' records and no more than $90$ patients' records.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display message.\n",
    "display(\n",
    "    Markdown(\n",
    "f\"\"\"\n",
    "Running our script to calculate the prevalence of our caseness variable shows that:\n",
    "- the prevalence of 'Possible caseness' is ${round(possibleCaseness_prevalence,3):,}\\%$, which equates to a redacted and rounded count of ${int(possibleCaseness_count):,}$\n",
    "- the prevalence of 'Definite caseness' is ${round(definiteCaseness_prevalence,3):,}\\%$, which equates to a redacted and rounded count of ${int(definiteCaseness_count):,}$\n",
    "\n",
    "Our simulations suggested upper- and lower-bound scaling factors of $0.7$ and $1.4$ to ensure  feature sets have at least $80\\%$ normalised mutual information\n",
    "with the caseness variables, in the best-case scenario.\n",
    "\n",
    "These data mean that:\n",
    "- for the 'Possible caseness' variable, we will only consider feature sets that are present in at least ${int(possibleCaseness_count_LB):,}$\n",
    "patients' records and no more than ${int(possibleCaseness_count_UB):,}$ patients' records.\n",
    "- for the 'Definite caseness' variable, we will only consider feature sets that are present in at least ${int(definiteCaseness_count_LB):,}$\n",
    "patients' records and no more than ${int(definiteCaseness_count_UB):,}$ patients' records.\n",
    "\"\"\"\n",
    "       )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
