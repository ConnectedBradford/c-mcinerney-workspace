{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88b3fd8b-4a06-49f7-92d8-0d3354f47c67",
   "metadata": {},
   "source": [
    "# Minimum reproducible example: Kernel drop\n",
    "\n",
    "The purpose of this script is to provide a minimal reproducible example of the issue I keep facing. The issue is that the Python 3 kernel in my Jupyter notebook inconsistently needs restarting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5006c06-4c2b-4b30-935e-f0e4264fbb3e",
   "metadata": {},
   "source": [
    "### Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a847d4c7-fc0d-48f2-8e45-2722a01221bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import EntropyHub\n",
    "except:\n",
    "    !pip install EntropyHub\n",
    "    import EntropyHub\n",
    "import itertools\n",
    "import numpy\n",
    "import pandas\n",
    "try:\n",
    "    import pyinform\n",
    "except:\n",
    "    !pip install pyinform\n",
    "    import pyinform\n",
    "import random\n",
    "import time\n",
    "import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7990a0f-704b-44ec-a8f0-b8154cc78fef",
   "metadata": {},
   "source": [
    "### Define functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9f11d2-edad-4e92-a763-b3cccfefd4a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chaoticlifeentropyfs(pt_timeline):\n",
    "    '''\n",
    "    There are two categories of entropy-based feature sets for both appointments and did-not-attends:\n",
    "    Sequential\n",
    "    1.\tactiveInformation\n",
    "    2.\tentropyRate\n",
    "    Summative\n",
    "    3.\tspectralEntropy\n",
    "    4.\tsampleEntropy\n",
    "    5.\teoe (entropy of entropy)\n",
    "    6.\taverageEntropy\n",
    "    7.\tbubbleEntropy\n",
    "    Use the following parameters for all summative entropy statistics other than spectral entropy, which doesn't require them:\n",
    "    -\tobs = three-monthly count, enough to amass a period of use.\n",
    "    -\twindow breath (\"embedding dimension\") = 4, to indicate a year's worth of appointments.\n",
    "    -\twindow shift (\"embedding time delay\") = 1, to be sensitive to quarterly changes in behaviour.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Set parameters.\n",
    "    # ## Set warnings parameter to handle divide-by-zero issues with spectral entropy.\n",
    "    warnings.filterwarnings(\"error\")\n",
    "    # ## Window breath (\"embedding dimension\") = 4, to indicate a year's worth of appointments.\n",
    "    embeddingDimension = 4\n",
    "    # ## Window shift (\"embedding time delay\") = 1, to be sensitive to quarterly changes in behaviour.\n",
    "    embeddingTimeDelay = 1\n",
    "    # ## Length of the patient's timeline.\n",
    "    len_timeline = len(pt_timeline)\n",
    "    # Convert pt_timeline into a numpy.array.\n",
    "    pt_timeline = numpy.array(pt_timeline)\n",
    "    \n",
    "    # activeInformation\n",
    "    # ...\n",
    "    if len_timeline <= embeddingDimension:\n",
    "        activeInformation = None\n",
    "    else:\n",
    "        try:\n",
    "            activeInformation = \\\n",
    "                pyinform.activeinfo.active_info(pt_timeline, k = embeddingDimension)\n",
    "        except:\n",
    "            activeInformation = None\n",
    "    \n",
    "    # entropyRate\n",
    "    # ...\n",
    "    if len_timeline <= embeddingDimension:\n",
    "        entropyRate = None\n",
    "    else:\n",
    "        try:\n",
    "            entropyRate = \\\n",
    "                pyinform.entropyrate.entropy_rate(pt_timeline, k = embeddingDimension)\n",
    "        except:\n",
    "            entropyRate = None\n",
    "    \n",
    "    # spectralEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        spectralEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            spectralEntropy, _ = EntropyHub.SpecEn(pt_timeline)\n",
    "        except RuntimeWarning:\n",
    "            spectralEntropy = None\n",
    "    \n",
    "    # sampleEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        sampleEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            sampleEntropy, _, _ = \\\n",
    "                EntropyHub.SampEn(pt_timeline, m = embeddingDimension, tau = embeddingTimeDelay)\n",
    "            sampleEntropy = sampleEntropy[-1]\n",
    "        except:\n",
    "            sampleEntropy = None\n",
    "\n",
    "    # eoe and averageEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        eoe = None\n",
    "        averageEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            eoe, averageEntropy, _ = \\\n",
    "                EntropyHub.EnofEn(pt_timeline, tau = embeddingDimension, S = math.floor(len_timeline / 4) )\n",
    "        except:\n",
    "            eoe = None\n",
    "            averageEntropy = None\n",
    "\n",
    "    # bubbleEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        bubbleEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            bubbleEntropy, _ = EntropyHub.BubbEn(pt_timeline, m = embeddingDimension, tau = embeddingTimeDelay)\n",
    "            bubbleEntropy = bubbleEntropy[-1]\n",
    "        except:\n",
    "            bubbleEntropy = None\n",
    "    \n",
    "    # Package the output.\n",
    "    ls_entropyBasedFeatureSets = \\\n",
    "        [\n",
    "        activeInformation\n",
    "        ,entropyRate\n",
    "        ,spectralEntropy\n",
    "        ,sampleEntropy\n",
    "        ,eoe\n",
    "        ,averageEntropy\n",
    "        ,bubbleEntropy\n",
    "        ]\n",
    "    \n",
    "    return ls_entropyBasedFeatureSets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2d906-735a-4194-b63d-0d1794921869",
   "metadata": {},
   "source": [
    "### Manufacture data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8c65e8-3533-4c0e-98d5-108e00f5975c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set count of patients.\n",
    "n_patient = 200000\n",
    "\n",
    "# Set earliest and latest permitted years.\n",
    "year_min = 2013\n",
    "year_max = 2023\n",
    "\n",
    "# Set maximum permitted count of appointments per quarter.\n",
    "max_appts_per_qtr = 10\n",
    "\n",
    "# Set `quarters` constant.\n",
    "quarters = list(range(1,4+1))\n",
    "\n",
    "# Make data.\n",
    "for i_patient in range(n_patient):\n",
    "    # Randomly set patient's earliest and latest year.\n",
    "    pt_year_min = random.randint(year_min, year_max)\n",
    "    pt_year_max = random.randint(pt_year_min, year_max)\n",
    "    \n",
    "    # Create patient's timeline of years and quarters.\n",
    "    pt_yearline = list(range(pt_year_min, pt_year_max+1))\n",
    "    pt_timeline = []\n",
    "    for i_year in range(len(pt_yearline)):\n",
    "        for i_quarter in range(len(quarters)):\n",
    "            pt_timeline.append( ( i_patient+1, pt_yearline[i_year],\n",
    "                                 quarters[i_quarter], random.randint(0, max_appts_per_qtr+1) ) )\n",
    "\n",
    "    # Make or append to `bq_countAppointmentsPerQuarter` and `bq_countDNAsPerQuarter` pandas.DataFrames.\n",
    "    # Note: countDNAsPerQuarter must be less than countAppointmentsPerQuarter.\n",
    "    if i_patient == 0:\n",
    "        bq_countAppointmentsPerQuarter = \\\n",
    "            pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_appointment',\n",
    "                                                     'quarter_appointment', 'countAppointmentsPerQuarter'])\n",
    "\n",
    "        bq_countDNAsPerQuarter = \\\n",
    "            pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_DNA', 'quarter_DNA', 'countDNAsPerQuarter'])\n",
    "        for i_row in range(len(bq_countDNAsPerQuarter)):\n",
    "            bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row] = random.randint(0, bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row])\n",
    "    else:\n",
    "        bq_countAppointmentsPerQuarter = \\\n",
    "            bq_countAppointmentsPerQuarter.append(\n",
    "                pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_appointment',\n",
    "                                                         'quarter_appointment', 'countAppointmentsPerQuarter'])\n",
    "            )\n",
    "        \n",
    "        temp_bq_countDNAsPerQuarter = \\\n",
    "            pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_DNA', 'quarter_DNA', 'countDNAsPerQuarter'])\n",
    "        for i_row in range(len(temp_bq_countDNAsPerQuarter)):\n",
    "            temp_bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row] = random.randint(0, temp_bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row])\n",
    "        bq_countDNAsPerQuarter = bq_countDNAsPerQuarter.append(temp_bq_countDNAsPerQuarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbefed8-32fd-4372-950e-c0198ca41920",
   "metadata": {},
   "source": [
    "### Run problem code.\n",
    "\n",
    "The code cell below is lifted directly from UNSEEN_create_feature_sets.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfb8f9c-23cd-4837-907a-da047e3fb43d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No person_id values have already been processed. All person_id value will be processed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20001/200000 [08:24<2:15:39, 22.12 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n",
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39998/200000 [16:52<1:04:32, 41.32 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40008/200000 [16:52<2:24:11, 18.49 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59997/200000 [25:16<59:52, 38.97 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60005/200000 [25:17<2:58:09, 13.10 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79999/200000 [33:44<50:30, 39.60 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80007/200000 [33:45<3:01:52, 11.00 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99996/200000 [42:12<39:21, 42.34 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100005/200000 [42:14<2:41:00, 10.35 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 119999/200000 [50:39<34:01, 39.18 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120007/200000 [50:41<2:38:41,  8.40 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 139997/200000 [59:07<25:10, 39.73 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140006/200000 [59:09<2:12:43,  7.53 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159998/200000 [1:07:36<17:12, 38.74 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160006/200000 [1:07:39<1:44:46,  6.36 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 179998/200000 [1:16:06<09:10, 36.32 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180007/200000 [1:16:10<53:51,  6.19 patients/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 199998/200000 [1:24:35<00:00, 40.18 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [1:24:38<00:00, 39.38 patients/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pid_processed' (list)\n",
      "It took 5078.947779417038 to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'entropyBasedFS' (DataFrame)\n",
      "Stored 'pid_processed' (list)\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# The FOR loop version.#\n",
    "########################\n",
    "\n",
    "# Set iterator.\n",
    "ls_pids = list(set(numpy.concatenate((bq_countAppointmentsPerQuarter.person_id.unique(), bq_countDNAsPerQuarter.person_id.unique()))))\n",
    "ls_pids.sort()\n",
    "\n",
    "# Set storage.\n",
    "ls_entropyBased_fs_appts = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "ls_entropyBased_fs_DNAs = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "\n",
    "# Set batch size.\n",
    "batch_size = 20000\n",
    "# ****************************\n",
    "# I have to add the following block of code to cope with the Jupyter kernel intermittently crashing.\n",
    "# The code block below checks if `pid_processed` already exists in store, and removes the person IDs\n",
    "# that have already been processed from the `ls_pids` list.\n",
    "#\n",
    "# Check if `pid_processed` exists.\n",
    "try:\n",
    "    if len(pid_processed) > 0:\n",
    "        # The following code only runs if `pid_processed` exists and is loaded.\n",
    "        ls_pids = list(set(ls_pids).difference(set(pid_processed)))\n",
    "        print(\"\\nSome person_id values have already been processed. The `ls_pid` iterator will be shortened accordingly.\\n\")\n",
    "    else:\n",
    "        # If `pid_processed` does not exist, then I am starting from scratch\n",
    "        pid_processed = []\n",
    "        print(\"\\nNo person_id values have already been processed. All person_id value will be processed.\\n\")\n",
    "except:\n",
    "    # If `pid_processed` does not exist, then I am starting from scratch\n",
    "    pid_processed = []\n",
    "    print(\"\\nNo person_id values have already been processed. All person_id value will be processed.\\n\")\n",
    "# ****************************\n",
    "\n",
    "# Check if there are any patient records that still need to be processed.\n",
    "if len(ls_pids) != 0:\n",
    "    # Set timer.\n",
    "    t1 = time.time()\n",
    "    # Set counter for interim storage.\n",
    "    store_counter = 1\n",
    "    # Set counter for storage batch.\n",
    "    try:\n",
    "        if len(entropyBasedFS) >= batch_size:\n",
    "            store_batch_num = 1\n",
    "        else:\n",
    "            store_batch_num = 0\n",
    "    except:\n",
    "        store_batch_num = 0\n",
    "    \n",
    "    # Do the loop.\n",
    "    for pid in tqdm.tqdm(ls_pids, unit = ' patients'):\n",
    "        # Extract this particular patient's range of active years.\n",
    "        pt_years = \\\n",
    "            bq_countAppointmentsPerQuarter.loc[bq_countAppointmentsPerQuarter.person_id == pid, 'year_appointment'].append(\n",
    "             bq_countDNAsPerQuarter.loc[bq_countDNAsPerQuarter.person_id == pid, 'year_DNA'])\n",
    "\n",
    "        pt_years_lsrange =  pandas.DataFrame(\n",
    "            data = { 'year' : list( range( min(pt_years), max(pt_years) ) ) }\n",
    "            )\n",
    "        # Create a timeline of years and quarters for this particular patient.\n",
    "        pt_quarters = pandas.DataFrame( data = {'qtr': [1,2,3,4]} )\n",
    "        pt_timeline = pt_years_lsrange.merge(pt_quarters, how = 'cross')\n",
    "\n",
    "        # Join the patient's actual count of appointments-per-quarter-per-year to their timeline.\n",
    "        pt_appts = bq_countAppointmentsPerQuarter.loc[bq_countAppointmentsPerQuarter.person_id == pid, :]\n",
    "        pt_timeline_appts = \\\n",
    "            pandas.merge(pt_timeline, pt_appts, how = 'left',\n",
    "                         left_on = ['year', 'qtr'],\n",
    "                         right_on = ['year_appointment',\n",
    "                                     'quarter_appointment']).loc[:,'countAppointmentsPerQuarter'].fillna(0).astype(int)\n",
    "\n",
    "        # Repeat for did-not-attend events.\n",
    "        pt_DNAs = bq_countDNAsPerQuarter.loc[bq_countDNAsPerQuarter.person_id == pid, :]\n",
    "        pt_timeline_DNAs = \\\n",
    "            pandas.merge(pt_timeline, pt_DNAs, how = 'left',\n",
    "                         left_on = ['year', 'qtr'],\n",
    "                         right_on = ['year_DNA',\n",
    "                                     'quarter_DNA']).loc[:,'countDNAsPerQuarter'].fillna(0).astype(int)\n",
    "\n",
    "        # Create the entropy-based feature sets.\n",
    "        pt_entropyStats_appts = chaoticlifeentropyfs(pt_timeline_appts)\n",
    "        ls_entropyBased_fs_appts.append([pid] + pt_entropyStats_appts)\n",
    "        pt_entropyStats_DNAs = chaoticlifeentropyfs(pt_timeline_DNAs)\n",
    "        ls_entropyBased_fs_DNAs.append([pid] + pt_entropyStats_DNAs)\n",
    "        pid_processed.append(pid)\n",
    "        \n",
    "        # Check if store threshold has been reached.\n",
    "        if store_counter == batch_size:\n",
    "            # If it has been reached, then add to the interim store.\n",
    "            #\n",
    "            if store_batch_num == 0:\n",
    "                entropyBasedFS = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "                entropyBasedFS_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "                entropyBasedFS = entropyBasedFS.merge(entropyBasedFS_DNAs\n",
    "                                                      ,how = 'outer'\n",
    "                                                      ,on = 'person_id')\n",
    "                entropyBasedFS.set_axis(\n",
    "                    ['person_id', 'activeInformationAppts', 'entropyRateAppts', 'spectralEntropyAppts', 'sampleEntroptAppts'\n",
    "                     , 'eoeAppts', 'averageEntropyAppts', 'bubbleEntropyAppts', 'activeInformationDNAs', 'entropyRateDNAs'\n",
    "                     ,'spectralEntropyDNAs', 'sampleEntropyDNAs', 'eoeDNAs', 'averageEntropyDNAs', 'bubbleEntropyDNAs']\n",
    "                    ,axis = 1\n",
    "                    ,inplace = True\n",
    "                )\n",
    "            else:\n",
    "                # Define appendages\n",
    "                appendage = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "                appendage_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "                appendage = appendage.merge(appendage_DNAs, how = 'outer', on = 'person_id')\n",
    "\n",
    "                # Append.\n",
    "                entropyBasedFS = entropyBasedFS.append(appendage)\n",
    "            \n",
    "            # Store the storage dataframe.\n",
    "            %store entropyBasedFS pid_processed\n",
    "            \n",
    "            # Reset the temporary storage.\n",
    "            ls_entropyBased_fs_appts = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "            ls_entropyBased_fs_DNAs = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "            \n",
    "            # Reset `store_counter`.\n",
    "            store_counter = 1\n",
    "            \n",
    "            # Update `store_batch_num`.\n",
    "            store_batch_num += 1\n",
    "        else:\n",
    "            # Update `store_counter`.\n",
    "            store_counter += 1\n",
    "    \n",
    "    print(f'It took {time.time() - t1} to process.')\n",
    "else:\n",
    "    print(\"No person_id values remain in `ls_pids`\\n\")\n",
    "\n",
    "# Finall update to storage.\n",
    "#\n",
    "# Define appendages\n",
    "appendage = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "appendage_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "appendage = appendage.merge(appendage_DNAs, how = 'outer', on = 'person_id')\n",
    "\n",
    "# Append.\n",
    "try:\n",
    "    entropyBasedFS.append(appendage)\n",
    "except:\n",
    "    entropyBasedFS = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "    entropyBasedFS_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "    entropyBasedFS = entropyBasedFS.merge(entropyBasedFS_DNAs\n",
    "                                          ,how = 'outer'\n",
    "                                          ,on = 'person_id')\n",
    "    entropyBasedFS.set_axis(\n",
    "        ['person_id', 'activeInformationAppts', 'entropyRateAppts', 'spectralEntropyAppts', 'sampleEntroptAppts'\n",
    "         , 'eoeAppts', 'averageEntropyAppts', 'bubbleEntropyAppts', 'activeInformationDNAs', 'entropyRateDNAs'\n",
    "         ,'spectralEntropyDNAs', 'sampleEntropyDNAs', 'eoeDNAs', 'averageEntropyDNAs', 'bubbleEntropyDNAs']\n",
    "        ,axis = 1\n",
    "        ,inplace = True\n",
    "    )\n",
    "%store entropyBasedFS pid_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7331cad-d9b6-42b8-a1b0-6d4c0204850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>activeInformationAppts</th>\n",
       "      <th>entropyRateAppts</th>\n",
       "      <th>spectralEntropyAppts</th>\n",
       "      <th>sampleEntroptAppts</th>\n",
       "      <th>eoeAppts</th>\n",
       "      <th>averageEntropyAppts</th>\n",
       "      <th>bubbleEntropyAppts</th>\n",
       "      <th>activeInformationDNAs</th>\n",
       "      <th>entropyRateDNAs</th>\n",
       "      <th>...</th>\n",
       "      <th>eoe_x</th>\n",
       "      <th>averageEntropy_x</th>\n",
       "      <th>bubbleEntropy_x</th>\n",
       "      <th>activeInformation_y</th>\n",
       "      <th>entropyRate_y</th>\n",
       "      <th>spectralEntropy_y</th>\n",
       "      <th>sampleEntropy_y</th>\n",
       "      <th>eoe_y</th>\n",
       "      <th>averageEntropy_y</th>\n",
       "      <th>bubbleEntropy_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.155639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>199996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>199997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.423972</td>\n",
       "      <td>2.606465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.234901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>199998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>199999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.575871</td>\n",
       "      <td>2.117492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.526423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id  activeInformationAppts  entropyRateAppts  \\\n",
       "0              1                     NaN               NaN   \n",
       "1              2                1.500000               0.0   \n",
       "2              3                     NaN               NaN   \n",
       "3              4                     NaN               NaN   \n",
       "4              5                2.155639               0.0   \n",
       "...          ...                     ...               ...   \n",
       "19995     199996                     NaN               NaN   \n",
       "19996     199997                     NaN               NaN   \n",
       "19997     199998                     NaN               NaN   \n",
       "19998     199999                     NaN               NaN   \n",
       "19999     200000                     NaN               NaN   \n",
       "\n",
       "       spectralEntropyAppts  sampleEntroptAppts eoeAppts averageEntropyAppts  \\\n",
       "0                       NaN                 NaN     None                None   \n",
       "1                       NaN                 NaN     None                None   \n",
       "2                       NaN                 NaN     None                None   \n",
       "3                       NaN                 NaN     None                None   \n",
       "4                  0.646113                 NaN     None                None   \n",
       "...                     ...                 ...      ...                 ...   \n",
       "19995                   NaN                 NaN      NaN                 NaN   \n",
       "19996                   NaN                 NaN      NaN                 NaN   \n",
       "19997                   NaN                 NaN      NaN                 NaN   \n",
       "19998                   NaN                 NaN      NaN                 NaN   \n",
       "19999                   NaN                 NaN      NaN                 NaN   \n",
       "\n",
       "       bubbleEntropyAppts  activeInformationDNAs  entropyRateDNAs  ...  eoe_x  \\\n",
       "0                     NaN                    NaN              NaN  ...    NaN   \n",
       "1                     NaN               0.811278              0.0  ...    NaN   \n",
       "2                     NaN                    NaN              NaN  ...    NaN   \n",
       "3                     NaN                    NaN              NaN  ...    NaN   \n",
       "4                0.220703               1.750000              0.0  ...    NaN   \n",
       "...                   ...                    ...              ...  ...    ...   \n",
       "19995                 NaN                    NaN              NaN  ...   None   \n",
       "19996                 NaN                    NaN              NaN  ...   None   \n",
       "19997                 NaN                    NaN              NaN  ...   None   \n",
       "19998                 NaN                    NaN              NaN  ...   None   \n",
       "19999                 NaN                    NaN              NaN  ...   None   \n",
       "\n",
       "       averageEntropy_x bubbleEntropy_x activeInformation_y  entropyRate_y  \\\n",
       "0                   NaN             NaN                 NaN            NaN   \n",
       "1                   NaN             NaN                 NaN            NaN   \n",
       "2                   NaN             NaN                 NaN            NaN   \n",
       "3                   NaN             NaN                 NaN            NaN   \n",
       "4                   NaN             NaN                 NaN            NaN   \n",
       "...                 ...             ...                 ...            ...   \n",
       "19995              None             NaN            2.000000            0.0   \n",
       "19996              None        0.423972            2.606465            0.0   \n",
       "19997              None             NaN                 NaN            NaN   \n",
       "19998              None             NaN                 NaN            NaN   \n",
       "19999              None        0.575871            2.117492            0.0   \n",
       "\n",
       "       spectralEntropy_y  sampleEntropy_y  eoe_y  averageEntropy_y  \\\n",
       "0                    NaN              NaN    NaN               NaN   \n",
       "1                    NaN              NaN    NaN               NaN   \n",
       "2                    NaN              NaN    NaN               NaN   \n",
       "3                    NaN              NaN    NaN               NaN   \n",
       "4                    NaN              NaN    NaN               NaN   \n",
       "...                  ...              ...    ...               ...   \n",
       "19995                NaN              NaN   None              None   \n",
       "19996           0.603324              NaN   None              None   \n",
       "19997                NaN              NaN   None              None   \n",
       "19998                NaN              NaN   None              None   \n",
       "19999           0.723681              NaN   None              None   \n",
       "\n",
       "      bubbleEntropy_y  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "19995             NaN  \n",
       "19996        0.234901  \n",
       "19997             NaN  \n",
       "19998             NaN  \n",
       "19999        0.526423  \n",
       "\n",
       "[200000 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropyBasedFS"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-2.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-2:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
