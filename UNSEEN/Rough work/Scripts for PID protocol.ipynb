{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765be050",
   "metadata": {},
   "source": [
    "# \\<TITLE\\>\n",
    "\n",
    "The purpose of this notebook is to define the workflow set out in the PID.\n",
    "\n",
    "My Vertex workbench is broken so I have to simulate the outcome array and the feature-set array produced from the Connected Bradford dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867e8d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import math\n",
    "import sklearn.metrics\n",
    "n_persons = 699620"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cef64",
   "metadata": {},
   "source": [
    "## Protocol set out in PID\n",
    "\n",
    "### 1. Outcome array.\n",
    "Simulate the outcome array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f11923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcome_array = \\\n",
    "    pandas.DataFrame(data =\\\n",
    "                    {\n",
    "                        'person_id' : range(n_persons),\n",
    "                        'CMHD' : numpy.random.binomial(n = 1, p = 0.137, size = n_persons)\n",
    "                    }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a4ac5",
   "metadata": {},
   "source": [
    "### 2. Calculate the entropy of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b685eed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome entropy =  0.399 nats\n",
      "Outcome scaled entropy =  57.5 %\n"
     ]
    }
   ],
   "source": [
    "entropy_outcome = scipy.stats.entropy(outcome_array['CMHD'].value_counts(), base = math.e)\n",
    "entropy_outcome_scaled = round(entropy_outcome / math.log(2, math.e) * 100, 1)\n",
    "entropy_outcome = round(entropy_outcome, 3)\n",
    "print(\"Outcome entropy = \", entropy_outcome, \"nats\")\n",
    "print(\"Outcome scaled entropy = \", entropy_outcome_scaled, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2481310",
   "metadata": {},
   "source": [
    "### 3. Calculate hit rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7941611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate (all) = 13.6 %\n",
      "Hit rate (none) = 86.4 %\n",
      "Odds (No CMHD : CMHD) = 6.35 times less likely to have CMHD than to have it.\n"
     ]
    }
   ],
   "source": [
    "numerator = round(outcome_array['CMHD'].sum() / 5) * 5\n",
    "denominator = round(outcome_array['CMHD'].shape[0] / 5) * 5\n",
    "hitRate_all = round((numerator / denominator) * 100, 1)\n",
    "hitRate_none = 100 - hitRate_all\n",
    "Odds_noYes = hitRate_none / (100 - hitRate_none)\n",
    "print(\"Hit rate (all) =\", hitRate_all, \"%\")\n",
    "print(\"Hit rate (none) =\", hitRate_none, \"%\")\n",
    "print(\"Odds (No CMHD : CMHD) =\", round(Odds_noYes, 2), \"times less likely to have CMHD than to have it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed7c67",
   "metadata": {},
   "source": [
    "### 4. Create the feature-set array.\n",
    "Simulate a small feature-set array containing person_id and tallies of a few clinical codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf91571a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_levels_of_feature = 30\n",
    "prob_levels_of_feature = 0.05\n",
    "featureSet_array = \\\n",
    "    pandas.DataFrame(data =\\\n",
    "                    {\n",
    "                        'person_id' : range(n_persons),\n",
    "                        'f1'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f2'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f3'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f4'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f5'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f6'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f7'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f8'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f9'  : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f10' : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons),\n",
    "                        'f11' : numpy.random.binomial(n = n_levels_of_feature, p = prob_levels_of_feature, size = n_persons)\n",
    "                    }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cfdaa3",
   "metadata": {},
   "source": [
    "### 5. Create the Feature Set ID table.\n",
    "This table is a look-up table of feature-set IDs that shows which features make up the feature set. The table is instantiated on the assumption that feature sets will include no more than five features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781126e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the feature set id table.\n",
    "featureSet_ID_table = \\\n",
    "    pandas.DataFrame(columns = ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                               'Feature Set 3', 'Feature Set 4', 'Feature Set 5'\n",
    "                               ])\n",
    "# Populate the feature set id table with the individual features.\n",
    "featureSet_ID_table['Feature set ID'] = \\\n",
    "    featureSet_ID_table['Feature Set 1'] = \\\n",
    "        featureSet_array.columns[featureSet_array.columns != 'person_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a368d76f",
   "metadata": {},
   "source": [
    "### 6. Calculate the entropy of the feature sets.\n",
    "Calculate the entropy values but do not save any that are less than the entropy of the outcome. Justification for this action is based on the fact that the mutual information between the outcome variable and any feature will be less than or equal to the lesser entropy of the outcome or feature, i.e. $I(X_{i};CMHD) ≤ min\\{H(X_{i}), H(CMHD)\\}$. We don’t want any feature set that is worse than no feature set (i.e. having only the outcome prevalence to predict a random outcome value) so we don’t bother with any feature set that will lower the possible mutual information.\n",
    "\n",
    "Note: The code below converts all feature sets into binary, showing 0 when the value is zero (i.e. when a patient does not have a record of the SNOMED CT code) and 1 otherwise (i.e. when a patient has at least one record of the SNOMED CT code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7387099a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature entropies dropped = 0\n"
     ]
    }
   ],
   "source": [
    "feature_entropy = pandas.DataFrame(columns = ['Feature set', 'Entropy'])\n",
    "for i_featureSet in featureSet_array.columns[featureSet_array.columns != 'person_id']:\n",
    "    name_var = i_featureSet\n",
    "    binary_var = featureSet_array[i_featureSet] == 0\n",
    "    feature_entropy.loc[len(feature_entropy)] = \\\n",
    "        name_var, scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "\n",
    "# Drop the entropy records for any feature whose entropy is less than the entropy of the outcome.\n",
    "f_to_drop = feature_entropy[ feature_entropy['Entropy'] < entropy_outcome ].index\n",
    "features_dropped_due_to_low_entropy = feature_entropy.iloc[f_to_drop]\n",
    "nameDict={\"Feature set\":\"Dropped feature set\"}\n",
    "features_dropped_due_to_low_entropy = features_dropped_due_to_low_entropy.rename(columns=nameDict)\n",
    "feature_entropy.drop(f_to_drop, inplace = True)\n",
    "print(\"Number of feature entropies dropped =\", len(f_to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ea2c2",
   "metadata": {},
   "source": [
    "### 7. Calculate the two-way mutual information of the feature sets and the outcome.\n",
    "Two-way mutual information will only be calculated for those features whose entropies were greater than the outcome entropy. These dropped variables are indicated by the `features_dropped_due_to_low_entropy` pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645c73c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some or all features' entropy values were greater than or equal to the outcome entropy so two-way mutual information values will be calculated.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate storage for mutual information.\n",
    "feature_mutual_information = pandas.DataFrame(columns = ['Feature set', 'Mutual information'])\n",
    "\n",
    "# Define feature set for which mutual information will be calculated.\n",
    "f_to_calc = \\\n",
    "    set(featureSet_array.columns[featureSet_array.columns != 'person_id']).difference(\\\n",
    "      set(features_dropped_due_to_low_entropy['Dropped feature set']))\n",
    "\n",
    "# Calculate mutual information and store the values.\n",
    "if not f_to_calc:\n",
    "    print(\"No feature's entropy was greater than or equal to the outcome entropy so no two-way mutual information values will be calculated.\")\n",
    "else:\n",
    "    print(\"Some or all features' entropy values were greater than or equal to the outcome entropy so two-way mutual information values will be calculated.\")\n",
    "    for i_featureSet in f_to_calc:\n",
    "        name_var = i_featureSet\n",
    "        binary_var = featureSet_array[i_featureSet] == 0\n",
    "        feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "            name_var, sklearn.metrics.mutual_info_score(binary_var, outcome_array['CMHD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b7cef",
   "metadata": {},
   "source": [
    "### 8. Calculate the entropy and two-way mutual information of pair-composite feature sets and the outcome.\n",
    "The nested FOR LOOPs below also update the Feature Set ID table with the new features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d6b2b",
   "metadata": {},
   "source": [
    "### 9. Calculate the entropy and two-way mutual information of triplet-composite feature sets and the outcome.\n",
    "The composite feature sets will each be calculated separately to avoid having all the computation in one call, which risks losing everything if it crashes and places heavy demand on RAM.\n",
    "The code below is an obvious extension of the nested FOR LOOPs used in step 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977f0c0d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_featureSet in f_to_calc:\n",
    "    for j_featureSet in f_to_calc:\n",
    "        # Skip the iteration if the same feature set is selected twice.\n",
    "        if i_featureSet == j_featureSet:\n",
    "            continue\n",
    "            \n",
    "        for k_featureSet in f_to_calc:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if len(set([k_featureSet]) & set([i_featureSet, j_featureSet])) > 0:\n",
    "                continue\n",
    "\n",
    "            # Create the feature ID for the pair-composite feature set.\n",
    "            name_var = \"-\".join([i_featureSet, j_featureSet, k_featureSet])\n",
    "\n",
    "            # Update the feature set id table.\n",
    "            featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                    ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                                     'Feature Set 3']] = \\\n",
    "                [name_var, i_featureSet, j_featureSet, k_featureSet]\n",
    "\n",
    "            # Define the pair-composite feature set values.\n",
    "            # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "            # ## sets are 0, and 1 otherwise.\n",
    "            binary_var = \\\n",
    "                pandas.DataFrame(data = {\n",
    "                                          'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                          'j_binary_var' : featureSet_array[j_featureSet] == 0,\n",
    "                                          'k_binary_var' : featureSet_array[k_featureSet] == 0\n",
    "                                         }\n",
    "                                ).all(True)\n",
    "\n",
    "            # Calculate the entropy for the pair-composite feature set.\n",
    "            f_ent = scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "            if f_ent < entropy_outcome:\n",
    "                continue\n",
    "            else:\n",
    "                feature_entropy.loc[len(feature_entropy)] = name_var, f_ent\n",
    "\n",
    "            # Calculate the mutual information for the pair-composite feature set.\n",
    "            feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "                name_var, sklearn.metrics.mutual_info_score(binary_var, outcome_array['CMHD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f80675",
   "metadata": {},
   "source": [
    "### 10. Calculate the entropy and two-way mutual information of quadruplet-composite feature sets and the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a69e9ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_featureSet in f_to_calc:\n",
    "    for j_featureSet in f_to_calc:\n",
    "        # Skip the iteration if the same feature set is selected twice.\n",
    "        if i_featureSet == j_featureSet:\n",
    "            continue\n",
    "            \n",
    "        for k_featureSet in f_to_calc:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if len(set([k_featureSet]) & set([i_featureSet, j_featureSet])) > 0:\n",
    "                continue\n",
    "                \n",
    "            for l_featureSet in f_to_calc:\n",
    "                # Skip the iteration if the same feature set is selected twice.\n",
    "                if len(set([l_featureSet]) & set([i_featureSet, j_featureSet, k_featureSet])) > 0:\n",
    "                    continue\n",
    "\n",
    "                # Create the feature ID for the pair-composite feature set.\n",
    "                name_var = \"-\".join([i_featureSet, j_featureSet, k_featureSet, l_featureSet])\n",
    "\n",
    "                # Update the feature set id table.\n",
    "                featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                        ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                                         'Feature Set 3',  'Feature Set 4']] = \\\n",
    "                    [name_var, i_featureSet, j_featureSet, k_featureSet, l_featureSet]\n",
    "\n",
    "                # Define the pair-composite feature set values.\n",
    "                # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "                # ## sets are 0, and 1 otherwise.\n",
    "                binary_var = \\\n",
    "                    pandas.DataFrame(data = {\n",
    "                                              'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                              'j_binary_var' : featureSet_array[j_featureSet] == 0,\n",
    "                                              'k_binary_var' : featureSet_array[k_featureSet] == 0,\n",
    "                                              'l_binary_var' : featureSet_array[l_featureSet] == 0\n",
    "                                             }\n",
    "                                    ).all(True)\n",
    "\n",
    "                # Calculate the entropy for the pair-composite feature set.\n",
    "                f_ent = scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "                if f_ent < entropy_outcome:\n",
    "                    continue\n",
    "                else:\n",
    "                    feature_entropy.loc[len(feature_entropy)] = name_var, f_ent\n",
    "\n",
    "                # Calculate the mutual information for the pair-composite feature set.\n",
    "                feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "                    name_var, sklearn.metrics.mutual_info_score(binary_var, outcome_array['CMHD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21350e7",
   "metadata": {},
   "source": [
    "### 11. Calculate the entropy and two-way mutual information of quintuplet-composite feature sets and the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43494fd5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_featureSet in f_to_calc:\n",
    "    for j_featureSet in f_to_calc:\n",
    "        # Skip the iteration if the same feature set is selected twice.\n",
    "        if i_featureSet == j_featureSet:\n",
    "            continue\n",
    "            \n",
    "        for k_featureSet in f_to_calc:\n",
    "            # Skip the iteration if the same feature set is selected twice.\n",
    "            if len(set([k_featureSet]) & set([i_featureSet, j_featureSet])) > 0:\n",
    "                continue\n",
    "                \n",
    "            for l_featureSet in f_to_calc:\n",
    "                # Skip the iteration if the same feature set is selected twice.\n",
    "                if len(set([l_featureSet]) & set([i_featureSet, j_featureSet, k_featureSet])) > 0:\n",
    "                    continue\n",
    "                \n",
    "                for m_featureSet in f_to_calc:\n",
    "                    # Skip the iteration if the same feature set is selected twice.\n",
    "                    if len(set([m_featureSet]) & set([i_featureSet, j_featureSet, k_featureSet, l_featureSet])) > 0:\n",
    "                        continue\n",
    "\n",
    "                    # Create the feature ID for the pair-composite feature set.\n",
    "                    name_var = \"-\".join([i_featureSet, j_featureSet, k_featureSet, l_featureSet, m_featureSet])\n",
    "\n",
    "                    # Update the feature set id table.\n",
    "                    # ## Note: \n",
    "                    featureSet_ID_table.loc[len(featureSet_ID_table),\n",
    "                                            ['Feature set ID', 'Feature Set 1', 'Feature Set 2',\n",
    "                                             'Feature Set 3',  'Feature Set 4', 'Feature Set 5']] = \\\n",
    "                        [name_var, i_featureSet, j_featureSet, k_featureSet, l_featureSet, m_featureSet]\n",
    "\n",
    "                    # Define the pair-composite feature set values.\n",
    "                    # ## In this case, the pair-composite feature set is defined as 0 when both feature\n",
    "                    # ## sets are 0, and 1 otherwise.\n",
    "                    binary_var = \\\n",
    "                        pandas.DataFrame(data = {\n",
    "                                                  'i_binary_var' : featureSet_array[i_featureSet] == 0,\n",
    "                                                  'j_binary_var' : featureSet_array[j_featureSet] == 0,\n",
    "                                                  'k_binary_var' : featureSet_array[k_featureSet] == 0,\n",
    "                                                  'l_binary_var' : featureSet_array[l_featureSet] == 0,\n",
    "                                                  'm_binary_var' : featureSet_array[m_featureSet] == 0\n",
    "                                                 }\n",
    "                                        ).all(True)\n",
    "\n",
    "                    # Calculate the entropy for the pair-composite feature set.\n",
    "                    f_ent = scipy.stats.entropy(binary_var.value_counts(), base = math.e)\n",
    "                    if f_ent < entropy_outcome:\n",
    "                        continue\n",
    "                    else:\n",
    "                        feature_entropy.loc[len(feature_entropy)] = name_var, f_ent\n",
    "\n",
    "                    # Calculate the mutual information for the pair-composite feature set.\n",
    "                    feature_mutual_information.loc[len(feature_mutual_information)] = \\\n",
    "                        name_var, sklearn.metrics.mutual_info_score(binary_var, outcome_array['CMHD'])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
