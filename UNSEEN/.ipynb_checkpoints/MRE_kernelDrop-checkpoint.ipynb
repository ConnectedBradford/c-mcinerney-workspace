{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88b3fd8b-4a06-49f7-92d8-0d3354f47c67",
   "metadata": {},
   "source": [
    "# Minimum reproducible example: Kernel drop\n",
    "\n",
    "The purpose of this script is to provide a minimal reproducible example of the issue I keep facing. The issue is that the Python 3 kernel in my Jupyter notebook inconsistently needs restarting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c2cfa-ab46-4edd-a402-ef65b15a875a",
   "metadata": {},
   "source": [
    "### Load storemagic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d52b109-648b-47f2-baf8-f55453ee06a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bq_countAppointmentsPerQuarter             ->          person_id  year_appointment  quarter_appo\n",
      "bq_countDNAsPerQuarter                     ->          person_id  year_DNA  quarter_DNA  countDN\n",
      "caseness_array                             ->         person_id  caseness_1isYes\n",
      "0              \n",
      "caseness_prevalence                        -> 0.037882794096437675\n",
      "count_caseness                             -> 7880\n",
      "count_control                              -> 200130\n",
      "count_studyPopulation                      -> 208010\n",
      "database_id                                -> 'CB_FDM_PrimaryCare_V7'\n",
      "entropyBasedFS                             ->        person_id  activeInformationAppts  entropyR\n",
      "feature_set_array                          ->         person_id  abandonment  abandonment_CYP  a\n",
      "myIndexDate                                -> '2021-12-31'\n",
      "pid_processed                              -> [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n",
      "redaction_threshold                        -> 7\n",
      "server_id                                  -> 'yhcr-prd-phm-bia-core'\n",
      "sql_declarations                           -> \"\\nDECLARE myIndexDate DATE DEFAULT '2021-12-31';\\\n",
      "sql_studyPopulation                        -> \"\\nWITH\\n# Set up table of SNOMED-CT codes that wi\n",
      "target_round                               -> 10\n"
     ]
    }
   ],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5006c06-4c2b-4b30-935e-f0e4264fbb3e",
   "metadata": {},
   "source": [
    "### Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a847d4c7-fc0d-48f2-8e45-2722a01221bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import EntropyHub\n",
    "except:\n",
    "    !pip install EntropyHub\n",
    "    import EntropyHub\n",
    "import itertools\n",
    "import numpy\n",
    "import pandas\n",
    "try:\n",
    "    import pyinform\n",
    "except:\n",
    "    !pip install pyinform\n",
    "    import pyinform\n",
    "import random\n",
    "import time\n",
    "import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7990a0f-704b-44ec-a8f0-b8154cc78fef",
   "metadata": {},
   "source": [
    "### Define functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9f11d2-edad-4e92-a763-b3cccfefd4a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chaoticlifeentropyfs(pt_timeline):\n",
    "    '''\n",
    "    There are two categories of entropy-based feature sets for both appointments and did-not-attends:\n",
    "    Sequential\n",
    "    1.\tactiveInformation\n",
    "    2.\tentropyRate\n",
    "    Summative\n",
    "    3.\tspectralEntropy\n",
    "    4.\tsampleEntropy\n",
    "    5.\teoe (entropy of entropy)\n",
    "    6.\taverageEntropy\n",
    "    7.\tbubbleEntropy\n",
    "    Use the following parameters for all summative entropy statistics other than spectral entropy, which doesn't require them:\n",
    "    -\tobs = three-monthly count, enough to amass a period of use.\n",
    "    -\twindow breath (\"embedding dimension\") = 4, to indicate a year's worth of appointments.\n",
    "    -\twindow shift (\"embedding time delay\") = 1, to be sensitive to quarterly changes in behaviour.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Set parameters.\n",
    "    # ## Set warnings parameter to handle divide-by-zero issues with spectral entropy.\n",
    "    warnings.filterwarnings(\"error\")\n",
    "    # ## Window breath (\"embedding dimension\") = 4, to indicate a year's worth of appointments.\n",
    "    embeddingDimension = 4\n",
    "    # ## Window shift (\"embedding time delay\") = 1, to be sensitive to quarterly changes in behaviour.\n",
    "    embeddingTimeDelay = 1\n",
    "    # ## Length of the patient's timeline.\n",
    "    len_timeline = len(pt_timeline)\n",
    "    # Convert pt_timeline into a numpy.array.\n",
    "    pt_timeline = numpy.array(pt_timeline)\n",
    "    \n",
    "    # activeInformation\n",
    "    # ...\n",
    "    if len_timeline <= embeddingDimension:\n",
    "        activeInformation = None\n",
    "    else:\n",
    "        try:\n",
    "            activeInformation = \\\n",
    "                pyinform.activeinfo.active_info(pt_timeline, k = embeddingDimension)\n",
    "        except:\n",
    "            activeInformation = None\n",
    "    \n",
    "    # entropyRate\n",
    "    # ...\n",
    "    if len_timeline <= embeddingDimension:\n",
    "        entropyRate = None\n",
    "    else:\n",
    "        try:\n",
    "            entropyRate = \\\n",
    "                pyinform.entropyrate.entropy_rate(pt_timeline, k = embeddingDimension)\n",
    "        except:\n",
    "            entropyRate = None\n",
    "    \n",
    "    # spectralEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        spectralEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            spectralEntropy, _ = EntropyHub.SpecEn(pt_timeline)\n",
    "        except RuntimeWarning:\n",
    "            spectralEntropy = None\n",
    "    \n",
    "    # sampleEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        sampleEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            sampleEntropy, _, _ = \\\n",
    "                EntropyHub.SampEn(pt_timeline, m = embeddingDimension, tau = embeddingTimeDelay)\n",
    "            sampleEntropy = sampleEntropy[-1]\n",
    "        except:\n",
    "            sampleEntropy = None\n",
    "\n",
    "    # eoe and averageEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        eoe = None\n",
    "        averageEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            eoe, averageEntropy, _ = \\\n",
    "                EntropyHub.EnofEn(pt_timeline, tau = embeddingDimension, S = math.floor(len_timeline / 4) )\n",
    "        except:\n",
    "            eoe = None\n",
    "            averageEntropy = None\n",
    "\n",
    "    # bubbleEntropy\n",
    "    # ...\n",
    "    if len_timeline <= 10:\n",
    "        bubbleEntropy = None\n",
    "    else:\n",
    "        try:\n",
    "            bubbleEntropy, _ = EntropyHub.BubbEn(pt_timeline, m = embeddingDimension, tau = embeddingTimeDelay)\n",
    "            bubbleEntropy = bubbleEntropy[-1]\n",
    "        except:\n",
    "            bubbleEntropy = None\n",
    "    \n",
    "    # Package the output.\n",
    "    ls_entropyBasedFeatureSets = \\\n",
    "        [\n",
    "        activeInformation\n",
    "        ,entropyRate\n",
    "        ,spectralEntropy\n",
    "        ,sampleEntropy\n",
    "        ,eoe\n",
    "        ,averageEntropy\n",
    "        ,bubbleEntropy\n",
    "        ]\n",
    "    \n",
    "    return ls_entropyBasedFeatureSets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2d906-735a-4194-b63d-0d1794921869",
   "metadata": {},
   "source": [
    "### Manufacture data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c65e8-3533-4c0e-98d5-108e00f5975c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set count of patients.\n",
    "n_patient = 200000\n",
    "\n",
    "# Set earliest and latest permitted years.\n",
    "year_min = 2013\n",
    "year_max = 2023\n",
    "\n",
    "# Set maximum permitted count of appointments per quarter.\n",
    "max_appts_per_qtr = 10\n",
    "\n",
    "# Set `quarters` constant.\n",
    "quarters = list(range(1,4+1))\n",
    "\n",
    "# Make data.\n",
    "for i_patient in range(n_patient):\n",
    "    # Randomly set patient's earliest and latest year.\n",
    "    pt_year_min = random.randint(year_min, year_max)\n",
    "    pt_year_max = random.randint(pt_year_min, year_max)\n",
    "    \n",
    "    # Create patient's timeline of years and quarters.\n",
    "    pt_yearline = list(range(pt_year_min, pt_year_max+1))\n",
    "    pt_timeline = []\n",
    "    for i_year in range(len(pt_yearline)):\n",
    "        for i_quarter in range(len(quarters)):\n",
    "            pt_timeline.append( ( i_patient+1, pt_yearline[i_year],\n",
    "                                 quarters[i_quarter], random.randint(0, max_appts_per_qtr+1) ) )\n",
    "\n",
    "    # Make or append to `bq_countAppointmentsPerQuarter` and `bq_countDNAsPerQuarter` pandas.DataFrames.\n",
    "    # Note: countDNAsPerQuarter must be less than countAppointmentsPerQuarter.\n",
    "    if i_patient == 0:\n",
    "        bq_countAppointmentsPerQuarter = \\\n",
    "            pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_appointment',\n",
    "                                                     'quarter_appointment', 'countAppointmentsPerQuarter'])\n",
    "\n",
    "        bq_countDNAsPerQuarter = \\\n",
    "            pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_DNA', 'quarter_DNA', 'countDNAsPerQuarter'])\n",
    "        for i_row in range(len(bq_countDNAsPerQuarter)):\n",
    "            bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row] = random.randint(0, bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row])\n",
    "    else:\n",
    "        bq_countAppointmentsPerQuarter = \\\n",
    "            bq_countAppointmentsPerQuarter.append(\n",
    "                pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_appointment',\n",
    "                                                         'quarter_appointment', 'countAppointmentsPerQuarter'])\n",
    "            )\n",
    "        \n",
    "        temp_bq_countDNAsPerQuarter = \\\n",
    "            pandas.DataFrame(pt_timeline, columns = ['person_id', 'year_DNA', 'quarter_DNA', 'countDNAsPerQuarter'])\n",
    "        for i_row in range(len(temp_bq_countDNAsPerQuarter)):\n",
    "            temp_bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row] = random.randint(0, temp_bq_countDNAsPerQuarter.countDNAsPerQuarter[i_row])\n",
    "        bq_countDNAsPerQuarter = bq_countDNAsPerQuarter.append(temp_bq_countDNAsPerQuarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbefed8-32fd-4372-950e-c0198ca41920",
   "metadata": {},
   "source": [
    "### Run problem code.\n",
    "\n",
    "The code cell below is lifted directly from UNSEEN_create_feature_sets.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb8f9c-23cd-4837-907a-da047e3fb43d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# The FOR loop version.#\n",
    "########################\n",
    "\n",
    "# Set iterator.\n",
    "ls_pids = list(set(numpy.concatenate((bq_countAppointmentsPerQuarter.person_id.unique(), bq_countDNAsPerQuarter.person_id.unique()))))\n",
    "ls_pids.sort()\n",
    "\n",
    "# Set storage.\n",
    "ls_entropyBased_fs_appts = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "ls_entropyBased_fs_DNAs = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "\n",
    "# Set batch size.\n",
    "batch_size = 20000\n",
    "# ****************************\n",
    "# I have to add the following block of code to cope with the Jupyter kernel intermittently crashing.\n",
    "# The code block below checks if `MRE_pid_processed` already exists in store, and removes the person IDs\n",
    "# that have already been processed from the `ls_pids` list.\n",
    "#\n",
    "# Check if `MRE_pid_processed` exists.\n",
    "try:\n",
    "    if len(MRE_pid_processed) > 0:\n",
    "        # The following code only runs if `MRE_pid_processed` exists and is loaded.\n",
    "        ls_pids = list(set(ls_pids).difference(set(MRE_pid_processed)))\n",
    "        print(\"\\nSome person_id values have already been processed. The `ls_pid` iterator will be shortened accordingly.\\n\")\n",
    "    else:\n",
    "        # If `MRE_pid_processed` does not exist, then I am starting from scratch\n",
    "        MRE_pid_processed = []\n",
    "        print(\"\\nNo person_id values have already been processed. All person_id value will be processed.\\n\")\n",
    "except:\n",
    "    # If `MRE_pid_processed` does not exist, then I am starting from scratch\n",
    "    MRE_pid_processed = []\n",
    "    print(\"\\nNo person_id values have already been processed. All person_id value will be processed.\\n\")\n",
    "# ****************************\n",
    "\n",
    "# Check if there are any patient records that still need to be processed.\n",
    "if len(ls_pids) != 0:\n",
    "    # Set timer.\n",
    "    t1 = time.time()\n",
    "    # Set counter for interim storage.\n",
    "    store_counter = 1\n",
    "    # Set counter for storage batch.\n",
    "    try:\n",
    "        if len(MRE_entropyBasedFS) >= batch_size:\n",
    "            store_batch_num = 1\n",
    "        else:\n",
    "            store_batch_num = 0\n",
    "    except:\n",
    "        store_batch_num = 0\n",
    "    \n",
    "    # Do the loop.\n",
    "    for pid in tqdm.tqdm(ls_pids, unit = ' patients'):\n",
    "        # Extract this particular patient's range of active years.\n",
    "        pt_years = \\\n",
    "            bq_countAppointmentsPerQuarter.loc[bq_countAppointmentsPerQuarter.person_id == pid, 'year_appointment'].append(\n",
    "             bq_countDNAsPerQuarter.loc[bq_countDNAsPerQuarter.person_id == pid, 'year_DNA'])\n",
    "\n",
    "        pt_years_lsrange =  pandas.DataFrame(\n",
    "            data = { 'year' : list( range( min(pt_years), max(pt_years) ) ) }\n",
    "            )\n",
    "        # Create a timeline of years and quarters for this particular patient.\n",
    "        pt_quarters = pandas.DataFrame( data = {'qtr': [1,2,3,4]} )\n",
    "        pt_timeline = pt_years_lsrange.merge(pt_quarters, how = 'cross')\n",
    "\n",
    "        # Join the patient's actual count of appointments-per-quarter-per-year to their timeline.\n",
    "        pt_appts = bq_countAppointmentsPerQuarter.loc[bq_countAppointmentsPerQuarter.person_id == pid, :]\n",
    "        pt_timeline_appts = \\\n",
    "            pandas.merge(pt_timeline, pt_appts, how = 'left',\n",
    "                         left_on = ['year', 'qtr'],\n",
    "                         right_on = ['year_appointment',\n",
    "                                     'quarter_appointment']).loc[:,'countAppointmentsPerQuarter'].fillna(0).astype(int)\n",
    "\n",
    "        # Repeat for did-not-attend events.\n",
    "        pt_DNAs = bq_countDNAsPerQuarter.loc[bq_countDNAsPerQuarter.person_id == pid, :]\n",
    "        pt_timeline_DNAs = \\\n",
    "            pandas.merge(pt_timeline, pt_DNAs, how = 'left',\n",
    "                         left_on = ['year', 'qtr'],\n",
    "                         right_on = ['year_DNA',\n",
    "                                     'quarter_DNA']).loc[:,'countDNAsPerQuarter'].fillna(0).astype(int)\n",
    "\n",
    "        # Create the entropy-based feature sets.\n",
    "        pt_entropyStats_appts = chaoticlifeentropyfs(pt_timeline_appts)\n",
    "        ls_entropyBased_fs_appts.append([pid] + pt_entropyStats_appts)\n",
    "        pt_entropyStats_DNAs = chaoticlifeentropyfs(pt_timeline_DNAs)\n",
    "        ls_entropyBased_fs_DNAs.append([pid] + pt_entropyStats_DNAs)\n",
    "        MRE_pid_processed.append(pid)\n",
    "        \n",
    "        # Check if store threshold has been reached.\n",
    "        if store_counter == batch_size:\n",
    "            # If it has been reached, then add to the interim store.\n",
    "            #\n",
    "            if store_batch_num == 0:\n",
    "                MRE_entropyBasedFS = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "                MRE_entropyBasedFS_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "                MRE_entropyBasedFS = MRE_entropyBasedFS.merge(MRE_entropyBasedFS_DNAs\n",
    "                                                      ,how = 'outer'\n",
    "                                                      ,on = 'person_id')\n",
    "                MRE_entropyBasedFS.set_axis(\n",
    "                    ['person_id', 'activeInformationAppts', 'entropyRateAppts', 'spectralEntropyAppts', 'sampleEntroptAppts'\n",
    "                     , 'eoeAppts', 'averageEntropyAppts', 'bubbleEntropyAppts', 'activeInformationDNAs', 'entropyRateDNAs'\n",
    "                     ,'spectralEntropyDNAs', 'sampleEntropyDNAs', 'eoeDNAs', 'averageEntropyDNAs', 'bubbleEntropyDNAs']\n",
    "                    ,axis = 1\n",
    "                    ,inplace = True\n",
    "                )\n",
    "            else:\n",
    "                # Define appendages\n",
    "                appendage = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "                appendage_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "                appendage = appendage.merge(appendage_DNAs, how = 'outer', on = 'person_id')\n",
    "\n",
    "                # Append.\n",
    "                MRE_entropyBasedFS = MRE_entropyBasedFS.append(appendage)\n",
    "            \n",
    "            # Store the storage dataframe.\n",
    "            %store MRE_entropyBasedFS MRE_pid_processed\n",
    "            \n",
    "            # Reset the temporary storage.\n",
    "            ls_entropyBased_fs_appts = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "            ls_entropyBased_fs_DNAs = [['person_id', 'activeInformation', 'entropyRate', 'spectralEntropy', 'sampleEntropy', 'eoe', 'averageEntropy', 'bubbleEntropy']]\n",
    "            \n",
    "            # Reset `store_counter`.\n",
    "            store_counter = 1\n",
    "            \n",
    "            # Update `store_batch_num`.\n",
    "            store_batch_num += 1\n",
    "        else:\n",
    "            # Update `store_counter`.\n",
    "            store_counter += 1\n",
    "    \n",
    "    print(f'It took {time.time() - t1} to process.')\n",
    "else:\n",
    "    print(\"No person_id values remain in `ls_pids`\\n\")\n",
    "\n",
    "# Finall update to storage.\n",
    "#\n",
    "# Define appendages\n",
    "appendage = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "appendage_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "appendage = appendage.merge(appendage_DNAs, how = 'outer', on = 'person_id')\n",
    "\n",
    "# Append.\n",
    "try:\n",
    "    MRE_entropyBasedFS.append(appendage)\n",
    "except:\n",
    "    MRE_entropyBasedFS = pandas.DataFrame(ls_entropyBased_fs_appts[1:], columns = ls_entropyBased_fs_appts[0])\n",
    "    MRE_entropyBasedFS_DNAs = pandas.DataFrame(ls_entropyBased_fs_DNAs[1:], columns = ls_entropyBased_fs_DNAs[0])\n",
    "    MRE_entropyBasedFS = entropyBasedFS.merge(MRE_entropyBasedFS_DNAs\n",
    "                                          ,how = 'outer'\n",
    "                                          ,on = 'person_id')\n",
    "    MRE_entropyBasedFS.set_axis(\n",
    "        ['person_id', 'activeInformationAppts', 'entropyRateAppts', 'spectralEntropyAppts', 'sampleEntroptAppts'\n",
    "         , 'eoeAppts', 'averageEntropyAppts', 'bubbleEntropyAppts', 'activeInformationDNAs', 'entropyRateDNAs'\n",
    "         ,'spectralEntropyDNAs', 'sampleEntropyDNAs', 'eoeDNAs', 'averageEntropyDNAs', 'bubbleEntropyDNAs']\n",
    "        ,axis = 1\n",
    "        ,inplace = True\n",
    "    )\n",
    "%store MRE_entropyBasedFS MRE_pid_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7331cad-d9b6-42b8-a1b0-6d4c0204850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRE_entropyBasedFS"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-2.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-2:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
