{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b40a57-f528-4f72-956d-7e135596aba1",
   "metadata": {},
   "source": [
    "# Multiprocessing practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d883db6-1c81-439a-873d-82634f512861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbb4ef-b1d7-437c-bf2b-2b508fa6773b",
   "metadata": {},
   "source": [
    "The current problem is that the parallel-pool methods aren't updating the drop_tally, batch, or the featureSet_MI dataframe.\n",
    "\n",
    "The simpler methods might also not be; I haven't checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4121310-2aa9-4e30-8e21-cd026cf97919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a7e401-1204-4548-8c64-63e84786c4ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run 'UNSEEN_helper_functions.ipynb'\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39afe1fb-da26-4972-a886-0bd55dcc87e9",
   "metadata": {},
   "source": [
    "Below are the libraries that would be imported if I ran 'UNSEEN_helper_functions.ipynb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa8e8ae-b74c-4bad-89a4-306d04cf02b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import numpy\n",
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "from datetime import date, datetime\n",
    "import itertools\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot\n",
    "from google.cloud import bigquery, exceptions\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from IPython import get_ipython\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet\n",
    "import pathlib\n",
    "import timeit\n",
    "import re\n",
    "import rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f5a501e-c629-4611-b952-4f0eb560e8b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if 'df_fs_database' not in globals():\n",
    "#    %run ./\"UNSEEN_create_database_feature_sets.ipynb\"\n",
    "my_featureSet_array = df_fs_database\n",
    "featureSet_array = my_featureSet_array.head()\n",
    "casenessVector = caseness_array[['person_id','CMHD']]\n",
    "m = 3\n",
    "representation = 'all'\n",
    "source = 'database'\n",
    "df_ppl_and_codes = df_ppl_and_codes\n",
    "global verbose\n",
    "verbose = True\n",
    "savelocation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db11a5c-9442-4ff1-bc7b-54956fb62527",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No save location provided.\n",
      "...Defaulting to ~/Mutual information saves/Pairs\n",
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "Calculating mutual information values...\n"
     ]
    }
   ],
   "source": [
    "# Check order of feature set. If not provided,\n",
    "# default to m = 1.    \n",
    "if m == None:\n",
    "    order_int = 1\n",
    "    order_label = \"Individuals\"\n",
    "    print(\"\\nNo value for m provided.\" +\n",
    "          \"\\n...Default value of m = 1 will be used.\")\n",
    "elif m == 1:\n",
    "    order_int = m\n",
    "    order_label = \"Individuals\"\n",
    "elif m == 2:\n",
    "    order_int = m\n",
    "    order_label = \"Pairs\"\n",
    "elif m == 3:\n",
    "    order_int = m\n",
    "    order_label = \"Triplets\"\n",
    "else:\n",
    "    print(\"\\n** Error: Integer value between 1\",\n",
    "          \"and 3 not supplied for m.**\\n\")\n",
    "\n",
    "# Check and set save location.\n",
    "if savelocation == None:\n",
    "    savelocation = \\\n",
    "       (\"Mutual information saves/\"+\\\n",
    "        order_label)\n",
    "    print(\"\\nNo save location provided.\" +\n",
    "          \"\\n...Defaulting to ~/\" + savelocation)    \n",
    "\n",
    "# ## Check encoding. If not provided, \n",
    "# ## default to OR encoding.\n",
    "if representation == None:\n",
    "    representation_label = \"ALL\"\n",
    "    print(\"\\nNo representation provided.\" +\n",
    "          \"\\n...Defaulting to '\" + representation_label + \"' representation.\")\n",
    "elif representation == \"all\":\n",
    "    representation_label = \"ALL\"\n",
    "elif representation == \"multi\":\n",
    "    representation_label = \"MULTI\"\n",
    "else:\n",
    "    print(\"\\n** Error: Representation value from \",\n",
    "          \"{'and', 'multi'} not provided.**\\n\")\n",
    "\n",
    "# ## Check the source argument is provided.\n",
    "if source == None:\n",
    "    print(\"\\n** Error: No source argument provided.\",\n",
    "          \"**\\n\")\n",
    "\n",
    "# ## Set save string for particular caseness variable.\n",
    "caseness_type = casenessVector.columns.values[-1]\n",
    "if caseness_type == 'CMHD': \n",
    "    caseness_label = 'multinomial'\n",
    "elif caseness_type == 'CMHD_dx_and_rx': \n",
    "    caseness_label = 'definite'\n",
    "elif caseness_type == 'CMHD_rx_not_dx': \n",
    "    caseness_label = 'possible'\n",
    "elif caseness_type == 'CMHD_control': \n",
    "    caseness_label = 'control'\n",
    "\n",
    "print(\"\\n\\n\\n****************************************\")  \n",
    "print(\"Calculating mutual information values...\")\n",
    "\n",
    "# Instantiate specific storage for mutual information.\n",
    "featureSet_MI = \\\n",
    "    pandas.DataFrame(columns = ['Feature_set', 'Mutual_information'])\n",
    "\n",
    "# Instantiate batch number.\n",
    "batch = 0\n",
    "\n",
    "# Instantiate tally of feature sets that are dropped due to low entropy.\n",
    "drop_tally = 0\n",
    "\n",
    "# Define entropy of the particular caseness variable.\n",
    "entropy_caseness = \\\n",
    "    scipy.stats.entropy(casenessVector.iloc[:,-1].value_counts(),\n",
    "                        base = math.e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f6c601-78ce-4a15-b640-daec9bfd937b",
   "metadata": {},
   "source": [
    "# **********************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5346e-3116-40ed-9fb6-9927075a866b",
   "metadata": {},
   "source": [
    "# Benchmark ways to call `processdatabasefs()`\n",
    "\n",
    "Firstly, set the count of SNOMED-CT codes, k, whose combinations will be assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f98c484c-b50a-487c-8974-2cc525eb2534",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "portion_size = 10\n",
    "n_workers = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b5deb-9ce8-4696-97ea-1153ac592587",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The trick to get multiprocessing to work in iPython is to call the function from another PY file rather than define the function within the current PY file.\n",
    "Sources:\n",
    " - https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac\n",
    " - https://stackoverflow.com/questions/57103984/why-cant-jupyter-notebooks-handle-multiprocessing-on-windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04afcf63-7fd5-4620-a7d4-ac156a3bd584",
   "metadata": {},
   "source": [
    "Below I assess the following options to expedite the processing of database feature sets:\n",
    "- FOR loop\n",
    "- `map()`\n",
    "- list comprehension\n",
    "- `itertools.starmap()`\n",
    "- `multiprocessing.Pool.map()`\n",
    "- `multiprocessing.Pool.imap_unordered()`\n",
    "- `multiprocessing.Pool.starmap()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026be400-9daf-419d-a0a5-c8fffa87be89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FOR loop with portioned generator\n",
    "\n",
    "Applies a function to items, whereby:\n",
    "- items are processed in series\n",
    "- one at a time\n",
    "- but only after converting all items to a list\n",
    "- results are returned in the order in which they were submitted."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd122128-5b55-427d-918c-c9d1c0edb348",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "import itertools\n",
    "\n",
    "# Define a function to portion my iterable.\n",
    "# https://stackoverflow.com/questions/51446327/python-3-generator-comprehension-to-generate-chunks-including-last\n",
    "def portion_maker(gen, portion_size):\n",
    "    it = iter(gen)\n",
    "    while True:\n",
    "        portion = [*itertools.islice(it, 0, portion_size)]\n",
    "        if portion:\n",
    "            yield portion\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    gen = itertools.combinations(df_fs_database.snomedcode[0:k], m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        for i_row in portion:\n",
    "            print(f\"This batch is {i_row}.\")\n",
    "            processdatabasefs(i_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864522c-d882-42ee-a6d9-8d5165123b1e",
   "metadata": {},
   "source": [
    "## `map()` with portioned generator\n",
    "\n",
    "Applies a function to items, whereby:\n",
    "- items are processed in series\n",
    "- one batch at a time\n",
    "- but only after converting all items to a list\n",
    "- results are returned as one dump when everything is ready."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e039040c-2515-4c9b-b415-9c9935f3c70a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "import itertools\n",
    "\n",
    "# Define a function to portion my iterable.\n",
    "# https://stackoverflow.com/questions/51446327/python-3-generator-comprehension-to-generate-chunks-including-last\n",
    "def portion_maker(gen, portion_size):\n",
    "    it = iter(gen)\n",
    "    while True:\n",
    "        portion = [*itertools.islice(it, 0, portion_size)]\n",
    "        if portion:\n",
    "            yield portion\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    gen = itertools.combinations(df_fs_database.snomedcode[0:k], m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        print(f\"This batch is {portion}.\")\n",
    "        list(map(processdatabasefs, portion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce18a212-6c54-4105-af52-deb54da253fd",
   "metadata": {},
   "source": [
    "## List comprehension with portioned generator\n",
    "\n",
    "Applies a function to items, whereby:\n",
    "- items are processed in series\n",
    "- in one batch\n",
    "- all items are processed before being converted to a list\n",
    "- results are returned in the order in which they were submitted."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0b8676e-735d-4299-addb-88037937cd48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "import itertools\n",
    "\n",
    "# Define a function to portion my iterable.\n",
    "# https://stackoverflow.com/questions/51446327/python-3-generator-comprehension-to-generate-chunks-including-last\n",
    "def portion_maker(gen, portion_size):\n",
    "    it = iter(gen)\n",
    "    while True:\n",
    "        portion = [*itertools.islice(it, 0, portion_size)]\n",
    "        if portion:\n",
    "            yield portion\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    gen = itertools.combinations(df_fs_database.snomedcode[0:k], m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        [processdatabasefs(i_row) for i_row in portion]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cab318-f47d-426f-881b-5398b9938f29",
   "metadata": {},
   "source": [
    "## `itertools.starmap` with portioned generator\n",
    "\n",
    "Like base `map()` but:\n",
    "- iterables of iterables are acceptable.\n",
    "\n",
    "The benefit of iterables is that they don't take as much memory to process."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f66af3a0-9ff5-4a8e-aa74-3f9cdb049623",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "import itertools\n",
    "\n",
    "# Define a function to portion my iterable.\n",
    "# https://stackoverflow.com/questions/51446327/python-3-generator-comprehension-to-generate-chunks-including-last\n",
    "def portion_maker(gen, portion_size):\n",
    "    it = iter(gen)\n",
    "    while True:\n",
    "        portion = [*itertools.islice(it, 0, portion_size)]\n",
    "        if portion:\n",
    "            yield portion\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    gen = itertools.combinations(df_fs_database.snomedcode[0:k], m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        print(f\"This batch is {portion}.\")\n",
    "        list(itertools.starmap(processdatabasefs, portion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b43ef-6709-451a-9f15-36a18fac2907",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `multiprocessing.Pool.map` with portioned generator, and n_workers = 4\n",
    "\n",
    "Like base `map()` but:\n",
    "- items are processed in parallel\n",
    "- but items are not converted into list to begin processing\n",
    "- results are returned in the order in which they were submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dfd68e1-a87f-484d-9012-1f4fe7ed62da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This batch is [(140004, 166001, 216004), (140004, 166001, 219006), (140004, 166001, 251007), (140004, 216004, 219006), (140004, 216004, 251007), (140004, 219006, 251007), (166001, 216004, 219006), (166001, 216004, 251007), (166001, 219006, 251007), (216004, 219006, 251007)].\n",
      "CPU times: user 69.3 ms, sys: 126 ms, total: 195 ms\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "#\n",
    "# The IPYNB file has already been run in this notebook but I'm repeating\n",
    "# the run based on guidance from this blog:\n",
    "# https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac\n",
    "import itertools\n",
    "from multiprocessing import set_start_method, Pool\n",
    "from UNSEEN_helper_functions import processdatabasefs, init_worker, portion_maker\n",
    "#set_start_method('spawn', force = True)\n",
    "#%run 'UNSEEN_helper_functions.ipynb'\n",
    "\n",
    "# Do the main work.\n",
    "if __name__ ==  '__main__':\n",
    "    # Make variable values that would otherwise exist within featuresetmi().\n",
    "    featureSet_MI = \\\n",
    "        pandas.DataFrame(columns = ['Feature_set', 'Mutual_information'])\n",
    "    batch = 0\n",
    "    drop_tally = 0\n",
    "    gen = itertools.combinations(df_fs_database.snomedcode[0:k], m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        print(f\"This batch is {portion}.\")\n",
    "        with Pool(processes = n_workers,\n",
    "                  initializer = init_worker,\n",
    "                  initargs = \\\n",
    "                      (\n",
    "                      df_ppl_and_codes,\n",
    "                      caseness_array,\n",
    "                      drop_tally,\n",
    "                      batch,\n",
    "                      featureSet_MI,\n",
    "                      entropy_caseness\n",
    "                      )) as pool:\n",
    "            list(pool.map(processdatabasefs,portion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f311a19-c865-41ae-8904-f80cbf33ed2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_tally = 0\n",
      "batch = 0\n"
     ]
    }
   ],
   "source": [
    "print(f'drop_tally = {drop_tally}')\n",
    "print(f'batch = {batch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db083db5-47ff-4004-86b3-e19d0581244d",
   "metadata": {},
   "source": [
    "## `multiprocessing.Pool.imap_unordered` with portioned generator, and n_workers = 4\n",
    "\n",
    "Like base `map()` but:\n",
    "- items are processed in parallel\n",
    "- items are not converted into list to begin processing\n",
    "- results are returned when they are complete, rather than in order in which they were submitted."
   ]
  },
  {
   "cell_type": "raw",
   "id": "59b07bb7-9512-44a2-a451-9ed959699ec9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "#\n",
    "# The IPYNB file has already been run in this notebook but I'm repeating\n",
    "# the run based on guidance from this blog:\n",
    "# https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "%run 'UNSEEN_helper_functions.ipynb'\n",
    "\n",
    "# Define a function to portion my iterable.\n",
    "#\n",
    "# https://stackoverflow.com/questions/51446327/python-3-generator-comprehension-to-generate-chunks-including-last\n",
    "def portion_maker(gen, portion_size):\n",
    "    it = iter(gen)\n",
    "    while True:\n",
    "        portion = [*itertools.islice(it, 0, portion_size)]\n",
    "        if portion:\n",
    "            yield portion\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    gen = itertools.combinations(df_fs_database.snomedcode[0:k], m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        print(f\"This batch is {portion}.\")\n",
    "        list(Pool(n_workers).imap_unordered(processdatabasefs, portion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d828b3-16b1-447e-940a-59159041460c",
   "metadata": {},
   "source": [
    "## `multiprocessing.Pool.starmap` with portioned generator, and n_workers = 4\n",
    "\n",
    "Like `itertools.starmap()` but:\n",
    "- iterable items are processed in parallel.\n",
    "\n",
    "The benefit of iterables is that they don't take as much memory to process."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb336968-2818-408c-b2de-354815612151",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Prerequisites\n",
    "#\n",
    "# The IPYNB file has already been run in this notebook but I'm repeating\n",
    "# the run based on guidance from this blog:\n",
    "# https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "%run 'UNSEEN_helper_functions.ipynb'\n",
    "\n",
    "# Define a function to portion my iterable.\n",
    "#\n",
    "# https://stackoverflow.com/questions/51446327/python-3-generator-comprehension-to-generate-chunks-including-last\n",
    "def portion_maker(gen, portion_size):\n",
    "    it = iter(gen)\n",
    "    while True:\n",
    "        portion = [*itertools.islice(it, 0, portion_size)]\n",
    "        if portion:\n",
    "            yield portion\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ ==  '__main__': \n",
    "    gen = itertools.combinations(df_fs_database.snomedcode, m)\n",
    "    for portion in portion_maker(gen, portion_size):\n",
    "        print(f\"This batch is {portion}.\")\n",
    "        list(Pool(n_workers).starmap(processdatabasefs, portion))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
